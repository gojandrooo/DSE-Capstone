{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2daf9aa5-463f-4feb-abc7-8a8c2ee0020a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dask.distributed import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39412817",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c9a2fb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.0'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabula.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7048cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tabula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df6fc0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file = \"../data/[file_name].xlsx\"\n",
    "# xl = pd.ExcelFile(file)\n",
    "# sheets = xl.sheet_names  # see all sheet names\n",
    "# sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08111050",
   "metadata": {},
   "outputs": [],
   "source": [
    "tabula.io.read_pdf?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "edaf9067",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Got stderr: Feb 02, 2023 2:09:47 PM org.apache.pdfbox.pdmodel.font.FileSystemFontProvider loadDiskCache\n",
      "WARNING: New fonts found, font cache will be re-built\n",
      "Feb 02, 2023 2:09:47 PM org.apache.pdfbox.pdmodel.font.FileSystemFontProvider <init>\n",
      "WARNING: Building on-disk font cache, this may take a while\n",
      "Feb 02, 2023 2:09:48 PM org.apache.pdfbox.pdmodel.font.FileSystemFontProvider <init>\n",
      "WARNING: Finished building on-disk font cache, found 784 fonts\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[   LANDFIRE Fire Behavior Fuel Model 40 Attribute Data Dictionary  \\\n",
       " 0                                                 NaN               \n",
       " 1                                           Attribute               \n",
       " 2                                                 NaN               \n",
       " 3                                               VALUE               \n",
       " 4                                               -9999               \n",
       " 5                                                  91               \n",
       " 6                                                  92               \n",
       " 7                                                  93               \n",
       " 8                                                  98               \n",
       " 9                                                  99               \n",
       " 10                                                101               \n",
       " 11                                                102               \n",
       " 12                                                103               \n",
       " 13                                                104               \n",
       " 14                                                105               \n",
       " 15                                                106               \n",
       " 16                                                107               \n",
       " 17                                                108               \n",
       " 18                                                109               \n",
       " 19                                                121               \n",
       " 20                                                122               \n",
       " 21                                                123               \n",
       " 22                                                124               \n",
       " 23                                                141               \n",
       " 24                                                142               \n",
       " 25                                                143               \n",
       " 26                                                144               \n",
       " 27                                                145               \n",
       " 28                                                146               \n",
       " 29                                                147               \n",
       " 30                                                148               \n",
       " 31                                                149               \n",
       " 32                                                161               \n",
       " 33                                                162               \n",
       " 34                                                163               \n",
       " 35                                                164               \n",
       " 36                                                165               \n",
       " 37                                                181               \n",
       " 38                                                182               \n",
       " 39                                                183               \n",
       " 40                                                184               \n",
       " 41                                                185               \n",
       " 42                                                186               \n",
       " 43                                                187               \n",
       " 44                                                188               \n",
       " 45                                                189               \n",
       " 46                                                201               \n",
       " \n",
       "                                            Unnamed: 0  \n",
       " 0                                                 NaN  \n",
       " 1                                         Description  \n",
       " 2                                                 NaN  \n",
       " 3   These fire behavior fuel models represent dist...  \n",
       " 4                                       Fill - NoData  \n",
       " 5                                                 NB1  \n",
       " 6                                                 NB2  \n",
       " 7                                                 NB3  \n",
       " 8                                                 NB8  \n",
       " 9                                                 NB9  \n",
       " 10                                                GR1  \n",
       " 11                                                GR2  \n",
       " 12                                                GR3  \n",
       " 13                                                GR4  \n",
       " 14                                                GR5  \n",
       " 15                                                GR6  \n",
       " 16                                                GR7  \n",
       " 17                                                GR8  \n",
       " 18                                                GR9  \n",
       " 19                                                GS1  \n",
       " 20                                                GS2  \n",
       " 21                                                GS3  \n",
       " 22                                                GS4  \n",
       " 23                                                SH1  \n",
       " 24                                                SH2  \n",
       " 25                                                SH3  \n",
       " 26                                                SH4  \n",
       " 27                                                SH5  \n",
       " 28                                                SH6  \n",
       " 29                                                SH7  \n",
       " 30                                                SH8  \n",
       " 31                                                SH9  \n",
       " 32                                                TU1  \n",
       " 33                                                TU2  \n",
       " 34                                                TU3  \n",
       " 35                                                TU4  \n",
       " 36                                                TU5  \n",
       " 37                                                TL1  \n",
       " 38                                                TL2  \n",
       " 39                                                TL3  \n",
       " 40                                                TL4  \n",
       " 41                                                TL5  \n",
       " 42                                                TL6  \n",
       " 43                                                TL7  \n",
       " 44                                                TL8  \n",
       " 45                                                TL9  \n",
       " 46                                                SB1  ,\n",
       "       202                                                SB2\n",
       " 0     203                                                SB3\n",
       " 1     204                                                SB4\n",
       " 2     NaN                                                NaN\n",
       " 3   Count       number of pixels for the corresponding value\n",
       " 4     NaN                                                NaN\n",
       " 5    FBFM                Display attribute. FBFM Description\n",
       " 6     NB1                                    Urban/Developed\n",
       " 7     NB2                                           Snow/Ice\n",
       " 8     NB3                                       Agricultural\n",
       " 9     NB8                                         Open Water\n",
       " 10    NB9                                             Barren\n",
       " 11    GR1  Short, sparse dry climate grass is short, natu...\n",
       " 12    GR2  Low load, dry climate grass primarily grass wi...\n",
       " 13    GR3  Low load, very coarse, humid climate grass con...\n",
       " 14    GR4  Moderate load, dry climate grass, continuous, ...\n",
       " 15    GR5  Low load, humid climate grass, fuelbed depth i...\n",
       " 16    GR6  Moderate load, continuous humid climate grass,...\n",
       " 17    GR7  High load, continuous dry climate grass, grass...\n",
       " 18    GR8  High load, very coarse, continuous, humid clim...\n",
       " 19    GR9  Very high load, dense, tall, humid climate gra...\n",
       " 20    GS1  Low load, dry climate grass-shrub shrub about ...\n",
       " 21    GS2  Moderate load, dry climate grass-shrub, shrubs...\n",
       " 22    GS3  Moderate load, humid climate grass-shrub, mode...\n",
       " 23    GS4  High load, humid climate grass-shrub, heavy gr...\n",
       " 24    SH1  Low load dry climate shrub, woody shrubs and s...\n",
       " 25    SH2  Moderate load dry climate shrub, woody shrubs ...\n",
       " 26    SH3  Moderate load, humid climate shrub, woody shru...\n",
       " 27    SH4  Low load, humid climate timber shrub, woody sh...\n",
       " 28    SH5  High load, dry climate shrub litter and woody ...\n",
       " 29    SH6  Low load, humid climate shrub, woody shrubs an...\n",
       " 30    SH7  Very high load, dry climate shrub, woody shrub...\n",
       " 31    SH8  High load, humid climate shrub, woody shrubs a...,\n",
       "                                                   SH9  \\\n",
       " 0                                                 TU1   \n",
       " 1                                                 TU2   \n",
       " 2                                                 TU3   \n",
       " 3                                                 TU4   \n",
       " 4                                                 TU5   \n",
       " 5                                                 TL1   \n",
       " 6                                                 TL2   \n",
       " 7                                                 TL3   \n",
       " 8                                                 TL4   \n",
       " 9                                                 TL5   \n",
       " 10                                                TL6   \n",
       " 11                                                TL7   \n",
       " 12                                                TL8   \n",
       " 13                                                TL9   \n",
       " 14                                                SB1   \n",
       " 15                                                SB2   \n",
       " 16                                                SB3   \n",
       " 17                                                SB4   \n",
       " 18                                                NaN   \n",
       " 19                                                  R   \n",
       " 20                                                  G   \n",
       " 21                                                  B   \n",
       " 22                                                RED   \n",
       " 23                                              GREEN   \n",
       " 24                                               BLUE   \n",
       " 25                                                NaN   \n",
       " 26  For more information, refer to: https://www.fs...   \n",
       " 27                                                NaN   \n",
       " \n",
       "    Very high load, humid climate shrub, woody shrubs and shrub litter, dense finely branched shrubs with fine\\rdead fuel, 4-6 feet tall, herbaceous may be present, spread rate and flame high  \n",
       " 0   Low load dry climate timber grass shrub, low l...                                                                                                                                           \n",
       " 1   Moderate load, humid climate timber-shrub, mod...                                                                                                                                           \n",
       " 2   Moderate load, humid climate timber grass shru...                                                                                                                                           \n",
       " 3   Dwarf conifer with understory, short conifer t...                                                                                                                                           \n",
       " 4   Very high load, dry climate timber shrub, heav...                                                                                                                                           \n",
       " 5   Low load compact conifer litter, compact fores...                                                                                                                                           \n",
       " 6   Low load broadleaf litter, broadleaf, hardwood...                                                                                                                                           \n",
       " 7   Moderate load conifer litter, moderate load co...                                                                                                                                           \n",
       " 8   Small downed logs moderate load of fine litter...                                                                                                                                           \n",
       " 9   High load conifer litter, light slash or dead ...                                                                                                                                           \n",
       " 10  Moderate load broadleaf litter, spread rate an...                                                                                                                                           \n",
       " 11  Large downed logs, heavy load forest litter, l...                                                                                                                                           \n",
       " 12  Long needle litter, moderate load long needle ...                                                                                                                                           \n",
       " 13  Very high load broadleaf litter, may be heavy ...                                                                                                                                           \n",
       " 14  Low load activity fuel, light dead and down ac...                                                                                                                                           \n",
       " 15  Moderate load activity fuel or low load blowdo...                                                                                                                                           \n",
       " 16  High load activity fuel or moderate load blowd...                                                                                                                                           \n",
       " 17  High load blowdown, heavy blowdown fuel, blowd...                                                                                                                                           \n",
       " 18                                                NaN                                                                                                                                           \n",
       " 19                      Red color value range 0 - 255                                                                                                                                           \n",
       " 20                    Green color value range 0 - 255                                                                                                                                           \n",
       " 21                     Blue color value range 0 - 255                                                                                                                                           \n",
       " 22                        Red color value range 0 - 1                                                                                                                                           \n",
       " 23                      Green color value range 0 - 1                                                                                                                                           \n",
       " 24                       Blue color value range 0 - 1                                                                                                                                           \n",
       " 25                                                NaN                                                                                                                                           \n",
       " 26                                                NaN                                                                                                                                           \n",
       " 27                                                NaN                                                                                                                                           ]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = \"../data/LF20_F40ADD_220.pdf\"\n",
    "data_dict = tabula.io.read_pdf(file, pages='all')\n",
    "data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd6507ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VALUE</th>\n",
       "      <th>FBFM40</th>\n",
       "      <th>R</th>\n",
       "      <th>G</th>\n",
       "      <th>B</th>\n",
       "      <th>RED</th>\n",
       "      <th>GREEN</th>\n",
       "      <th>BLUE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>91</td>\n",
       "      <td>NB1</td>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "      <td>0.407843</td>\n",
       "      <td>0.407843</td>\n",
       "      <td>0.407843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>92</td>\n",
       "      <td>NB2</td>\n",
       "      <td>225</td>\n",
       "      <td>225</td>\n",
       "      <td>225</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.882353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>93</td>\n",
       "      <td>NB3</td>\n",
       "      <td>255</td>\n",
       "      <td>237</td>\n",
       "      <td>237</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.929412</td>\n",
       "      <td>0.929412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>98</td>\n",
       "      <td>NB8</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>214</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.054902</td>\n",
       "      <td>0.839216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>99</td>\n",
       "      <td>NB9</td>\n",
       "      <td>77</td>\n",
       "      <td>110</td>\n",
       "      <td>112</td>\n",
       "      <td>0.301961</td>\n",
       "      <td>0.431373</td>\n",
       "      <td>0.439216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VALUE FBFM40    R    G    B       RED     GREEN      BLUE\n",
       "0     91    NB1  104  104  104  0.407843  0.407843  0.407843\n",
       "1     92    NB2  225  225  225  0.882353  0.882353  0.882353\n",
       "2     93    NB3  255  237  237  1.000000  0.929412  0.929412\n",
       "3     98    NB8    0   14  214  0.000000  0.054902  0.839216\n",
       "4     99    NB9   77  110  112  0.301961  0.431373  0.439216"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = \"../data/LF20_F40_220.csv\"\n",
    "raw_data = pd.read_csv(file)\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b39cc891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46, 8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53e08058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 46 entries, 0 to 45\n",
      "Data columns (total 8 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   VALUE   46 non-null     int64  \n",
      " 1   FBFM40  46 non-null     object \n",
      " 2   R       46 non-null     int64  \n",
      " 3   G       46 non-null     int64  \n",
      " 4   B       46 non-null     int64  \n",
      " 5   RED     46 non-null     float64\n",
      " 6   GREEN   46 non-null     float64\n",
      " 7   BLUE    46 non-null     float64\n",
      "dtypes: float64(3), int64(4), object(1)\n",
      "memory usage: 3.0+ KB\n"
     ]
    }
   ],
   "source": [
    "raw_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44a1838-8a23-47d5-9b3f-d10ca187e557",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ca4131-eccd-4f60-b386-65de44844dc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05381321-23b6-4e7c-a8b8-2bff03f0be76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b39ce1b-8f03-4892-9da0-21eefdde7106",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "579d3b4b-3c74-4e20-942c-06683335481f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['b', 'a']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(blah).difference(del_15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926a7b1c-04db-454e-9fe4-edc6823a1155",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a23478a7-c13b-4565-89bb-5bb58d87af87",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak_i15_mmh\n",
      "contributingarea_km2\n",
      "prophm23\n",
      "dnbr1000\n",
      "kf\n",
      "Fine fuel load\n",
      "SAV\n",
      "Packing ratio\n",
      "Extinction moisture content\n",
      "LNDS_RISKS\n",
      "fire_interval\n",
      "SedUn\n",
      "SuscFrac\n"
     ]
    }
   ],
   "source": [
    "# check the column order\n",
    "import pickle\n",
    "X_train, X_test, y_train, y_test = pickle.load(open(\"../data/train_test_data.pkl\", \"rb\"))\n",
    "\n",
    "for col in X_train.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bcda7d-47f5-44f7-903d-29996aa47a11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e12e515-6653-4436-a73b-a6b795052575",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d2ebeea-3ff5-4b5c-a5e6-93b871635239",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, dropout_rate):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(dropout_rate) # dropout to prevent overfitting\n",
    "        \n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(dropout_rate) # dropout to prevent overfitting\n",
    "        \n",
    "#         self.fc3 = nn.Linear(hidden_size, hidden_size)\n",
    "#         self.relu3 = nn.ReLU()\n",
    "#         self.dropout3 = nn.Dropout(dropout_rate) # dropout to prevent overfitting\n",
    "\n",
    "#         self.fc4 = nn.Linear(hidden_size, hidden_size)\n",
    "#         self.relu4 = nn.ReLU()\n",
    "#         self.dropout4 = nn.Dropout(dropout_rate) # dropout to prevent overfitting\n",
    "        \n",
    "        self.fc_out = nn.Linear(hidden_size, output_size)\n",
    "        self.sigmoid = nn.Sigmoid() # output to probability rather than bool\n",
    "        \n",
    "        # Initilize weights with Glorot\n",
    "        # need to decide on uniform vs normal distribution\n",
    "        # UNIFORM\n",
    "        nn.init.xavier_uniform_(self.fc1.weight)\n",
    "        nn.init.xavier_uniform_(self.fc2.weight)\n",
    "        # nn.init.xavier_uniform_(self.fc3.weight)\n",
    "        # nn.init.xavier_uniform_(self.fc4.weight)\n",
    "        nn.init.xavier_uniform_(self.fc_out.weight)\n",
    "        \n",
    "        # NORMAL\n",
    "        # nn.init.xavier_normal_(self.fc1.weight)\n",
    "        # nn.init.xavier_normal_(self.fc2.weight)\n",
    "        # nn.init.xavier_normal_(self.fc3.weight)\n",
    "        # nn.init.xavier_normal_(self.fc4.weight)\n",
    "        # nn.init.xavier_normal_(self.fc_out.weight)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu1(out)\n",
    "        out = self.dropout1(out)\n",
    "        \n",
    "        out = self.fc2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.dropout2(out)\n",
    "        \n",
    "#         out = self.fc3(out)\n",
    "#         out = self.relu3(out)\n",
    "#         out = self.dropout3(out)\n",
    "        \n",
    "#         out = self.fc4(out)\n",
    "#         out = self.relu4(out)\n",
    "#         out = self.dropout4(out)\n",
    "        \n",
    "        out = self.fc_out(out)\n",
    "        out = self.sigmoid(out)      \n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c7c1763-4fc0-48e5-891b-82f9b966218f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    'dropout_rate': 0.2,\n",
    "     'features': [\n",
    "         'peak_i15_mmh',\n",
    "          'SuscFrac',\n",
    "          'prophm23',\n",
    "          'Fine fuel load',\n",
    "          'Extinction moisture content',\n",
    "          'SAV',\n",
    "          'SedUn',\n",
    "          'dnbr1000',\n",
    "          'fire_interval',\n",
    "          'contributingarea_km2',\n",
    "          'Packing ratio',\n",
    "          'LNDS_RISKS',\n",
    "          'kf'],\n",
    "     'hidden_size': 100,\n",
    "     'lr': 0.01\n",
    "}\n",
    "\n",
    "input_size = 13\n",
    "hidden_size = model_params['hidden_size']\n",
    "output_size = 1\n",
    "dropout_rate = model_params['dropout_rate']\n",
    "learning_rate = model_params['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5678a94-369a-45bc-8431-fa7022f4a1e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Net(input_size, hidden_size, output_size, dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26d4ded3-bd4b-4ba1-9439-08d426fc89dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"../model/df_model_two_hidden.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57431c82-7b43-41cf-b845-6c582566030a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.eval of Net(\n",
       "  (fc1): Linear(in_features=13, out_features=100, bias=True)\n",
       "  (relu1): ReLU()\n",
       "  (dropout1): Dropout(p=0.2, inplace=False)\n",
       "  (fc2): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (relu2): ReLU()\n",
       "  (dropout2): Dropout(p=0.2, inplace=False)\n",
       "  (fc_out): Linear(in_features=100, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7873b18-5ee5-48b6-9237-56b774440c38",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('fc1.weight',\n",
       "              tensor([[-2.6873e-02, -2.4580e-01, -2.2315e-01,  ..., -6.5710e-02,\n",
       "                       -7.8055e-01,  4.2797e-01],\n",
       "                      [ 4.2614e-01, -6.6906e-01, -4.1993e-04,  ..., -1.3552e-01,\n",
       "                       -3.0696e-01, -5.1577e-01],\n",
       "                      [ 3.7397e-01,  9.9725e-02, -1.3402e-01,  ...,  1.0296e-01,\n",
       "                        4.9119e-01,  4.1338e-01],\n",
       "                      ...,\n",
       "                      [-5.2493e-01,  2.6015e-01, -5.0051e-03,  ..., -6.9454e-02,\n",
       "                        5.4605e-02,  3.4259e-01],\n",
       "                      [-8.7998e-01, -6.4932e-01,  3.3507e-01,  ..., -1.0559e-01,\n",
       "                       -2.9691e-01, -1.0083e+00],\n",
       "                      [-2.5192e-01, -2.5571e-01, -4.5685e-01,  ..., -2.1588e-01,\n",
       "                       -3.0663e-01,  8.9361e-01]])),\n",
       "             ('fc1.bias',\n",
       "              tensor([-0.2365, -0.2941, -0.2232, -0.8006, -0.0457, -0.5987, -0.4514, -0.0681,\n",
       "                      -0.5087, -0.8260,  0.0731, -0.2194, -1.1765, -0.1184, -0.1515, -0.7149,\n",
       "                      -0.5684, -0.2457, -0.4686, -0.5681, -0.1729, -0.7801, -0.4967,  0.1216,\n",
       "                       0.0135, -0.3559, -0.5279, -0.4907, -0.3504, -0.0825, -0.5937, -0.3405,\n",
       "                      -0.0415, -0.5291, -0.0043, -0.5243, -0.0121, -0.2648, -0.7755,  0.0409,\n",
       "                      -0.3817,  0.0372, -0.0194, -0.3593,  0.0363, -0.1584, -0.1488, -0.2238,\n",
       "                      -0.0715, -0.6397, -0.0821, -0.5513, -0.2746, -1.0419, -0.9016, -0.4545,\n",
       "                       0.0842, -0.8410, -0.2981, -0.3179, -0.7018, -0.8368, -0.0266, -0.0724,\n",
       "                      -0.1963, -0.4297,  0.0250, -0.3156, -0.7257, -0.5946, -0.3500, -0.5683,\n",
       "                      -0.7217,  0.1023, -0.8867, -0.4430, -0.5771, -0.3303, -0.4987, -0.6339,\n",
       "                       0.0498, -1.1735, -0.1306, -0.2679, -0.3012, -0.3145, -0.3248, -0.5837,\n",
       "                      -0.6660, -0.2472,  0.0269, -0.3714, -0.2042, -0.7080,  0.0109, -0.6221,\n",
       "                      -0.7982, -0.2934, -0.7343,  0.0492])),\n",
       "             ('fc2.weight',\n",
       "              tensor([[-0.2462, -0.0964, -0.2795,  ..., -0.1213,  0.0657,  0.5029],\n",
       "                      [-0.5403,  0.0477, -0.0020,  ..., -0.4956, -0.2541, -0.0169],\n",
       "                      [ 0.1911,  0.1064,  0.1739,  ..., -0.0654,  0.2075, -0.6014],\n",
       "                      ...,\n",
       "                      [ 0.0203,  0.0938, -0.1124,  ...,  0.0751, -0.4048,  0.0233],\n",
       "                      [ 0.2394,  0.0108, -0.2517,  ...,  0.0938,  0.1423, -0.2622],\n",
       "                      [-0.0256,  0.0514,  0.0015,  ..., -0.0038,  0.0735, -0.0447]])),\n",
       "             ('fc2.bias',\n",
       "              tensor([ 0.1453, -0.0515, -0.2235, -0.0079, -0.0886, -0.0706, -0.0983, -0.0502,\n",
       "                      -0.0218, -0.4150, -0.1210, -0.2818, -0.1134, -0.0793, -0.1686, -0.1823,\n",
       "                       0.3437, -0.0315, -0.1538, -0.1671,  0.3937,  0.0499,  0.1088, -0.0770,\n",
       "                      -0.1581,  0.1347, -0.0356,  0.2214, -0.1257,  0.0101,  0.1841, -0.0132,\n",
       "                      -0.0630,  0.0437,  0.0663, -0.1227,  0.2344, -0.0667,  0.1590,  0.1565,\n",
       "                       0.0228, -0.0353,  0.0521, -0.1334, -0.0575,  0.3418, -0.2136,  0.0591,\n",
       "                      -0.0367, -0.0806,  0.1705, -0.0909,  0.0491,  0.1396,  0.0033,  0.1688,\n",
       "                      -0.1666,  0.0018,  0.2793,  0.0601,  0.1384,  0.1640, -0.2880,  0.1996,\n",
       "                      -0.0163,  0.2199, -0.0184, -0.0370, -0.1065, -0.0960, -0.0009, -0.0894,\n",
       "                      -0.0643, -0.1483,  0.1429, -0.1350,  0.2244,  0.1619,  0.2386,  0.2335,\n",
       "                      -0.0093, -0.1202, -0.0060, -0.1292,  0.1084, -0.1276, -0.1840, -0.0684,\n",
       "                       0.0850,  0.5429,  0.0178,  0.4275,  0.0032,  0.0123,  0.2177,  0.1478,\n",
       "                       0.0037,  0.0212, -0.1404, -0.1247])),\n",
       "             ('fc_out.weight',\n",
       "              tensor([[ 0.6450,  0.6604,  0.9647, -0.1305,  0.2873,  0.1711,  0.7083, -1.0918,\n",
       "                        1.2600,  0.6685, -1.0257, -0.8137,  0.1094, -0.0082, -0.3340, -0.8235,\n",
       "                       -0.9697,  0.0507,  0.2862, -1.0944,  1.7464, -1.1726, -1.0552, -0.2445,\n",
       "                       -1.3992, -0.1611, -0.9393, -0.6191, -0.0481,  0.3051,  1.3435, -1.1099,\n",
       "                        0.1929,  0.3490,  0.4765, -1.0569,  0.4946,  0.0209,  0.4178,  0.4553,\n",
       "                       -0.3018,  0.2283, -0.1447,  0.1328,  0.1809, -0.5139, -0.7224,  0.1486,\n",
       "                        0.4152,  0.1378,  1.0298, -0.7720,  0.7659, -0.1254,  0.5233, -0.7963,\n",
       "                        0.4276,  0.3967,  0.1627, -0.9045,  0.9960,  0.2415, -0.5910, -0.2318,\n",
       "                       -0.3900,  1.4149, -0.6072, -0.3143, -0.6017, -0.5297,  0.9622, -0.2231,\n",
       "                        0.0657,  0.1183, -0.3156,  1.0978,  0.7541,  0.6706,  0.6390, -0.4361,\n",
       "                       -0.4869, -0.9772,  0.2060, -0.2812,  0.3308,  0.3253,  0.5273, -1.1600,\n",
       "                       -0.4741,  1.4166,  0.7439, -0.6863, -1.2894, -0.3113,  0.4658,  0.5860,\n",
       "                       -0.0428, -0.1752, -0.2691,  0.1457]])),\n",
       "             ('fc_out.bias', tensor([0.1356]))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bc99e5-d08d-49a0-9c1a-262bac282f34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ebfea5e1-bf90-4f04-aabf-7f07c6cd537f",
   "metadata": {},
   "source": [
    "# Prep Notebooks Rename\n",
    "\n",
    "check na's notebooks\n",
    "\n",
    "`data_v08_fire_interval.parquet` is when the first nulls drop off\n",
    "- should be in notebook 07, check that logic and handle NA's in notebook 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4f92836-4c39-4946-994e-c340b8d8db50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dca4f21e-3d8d-4e0e-abe4-87eb785a3fa5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data_v01_add_site_ids.parquet',\n",
       " 'data_v02_sites_catchment_fuelpars.parquet',\n",
       " 'data_v03_observations_catchment_fuelpars.parquet',\n",
       " 'data_v04_rocktype.parquet',\n",
       " 'data_v05_rocktype_randn.parquet',\n",
       " 'data_v06_geological_age.parquet',\n",
       " 'data_v07_landslide.parquet',\n",
       " 'data_v08_fire_interval.parquet']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefixed = [filename for filename in os.listdir('../data') if filename.startswith(\"data_v\")]\n",
    "prefixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "95d6923c-a617-4f29-ace4-20a87c0f74e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1550, 28) data_v01_add_site_ids.parquet\n",
      "(716, 14) data_v02_sites_catchment_fuelpars.parquet\n",
      "(1550, 42) data_v03_observations_catchment_fuelpars.parquet\n",
      "(1550, 44) data_v04_rocktype.parquet\n",
      "(1550, 44) data_v05_rocktype_randn.parquet\n",
      "(1550, 46) data_v06_geological_age.parquet\n",
      "(1550, 48) data_v07_landslide.parquet\n",
      "(1379, 49) data_v08_fire_interval.parquet\n"
     ]
    }
   ],
   "source": [
    "for file in prefixed:\n",
    "    data = gpd.read_parquet(\"../data/\" + file)\n",
    "    print(data.shape, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "774f6856-4f20-4daf-9e44-b9122c102910",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/data_v01_add_site_ids.parquet'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"../data/\" + prefixed[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "115ab448-9e27-4338-a7cc-8d473bcd9524",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "03339dd2-2948-4f5f-9e9b-701d78938c83",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_v01_add_site_ids.parquet\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['SiteID',\n",
       " 'acc015_mm',\n",
       " 'acc030_mm',\n",
       " 'acc060_mm',\n",
       " 'contributingarea_km2',\n",
       " 'database',\n",
       " 'dnbr1000',\n",
       " 'fire_id',\n",
       " 'fire_name',\n",
       " 'fire_segid',\n",
       " 'gaugedist_m',\n",
       " 'geom',\n",
       " 'kf',\n",
       " 'lat',\n",
       " 'lon',\n",
       " 'peak_i15_mmh',\n",
       " 'peak_i30_mmh',\n",
       " 'peak_i60_mmh',\n",
       " 'prophm23',\n",
       " 'response',\n",
       " 'state',\n",
       " 'stormaccum_mm',\n",
       " 'stormavgi_mmh',\n",
       " 'stormdate',\n",
       " 'stormdur_h',\n",
       " 'stormend',\n",
       " 'stormstart',\n",
       " 'year']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = prefixed[0]\n",
    "print(name)\n",
    "\n",
    "data = gpd.read_parquet(\"../data/\" + name) \n",
    "sorted(data.columns)\n",
    "#data.head()[[\"newarea\",\"geometry\",\"snapdist\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cf84e4-ea64-4eea-a0fa-4e3fc6a2a423",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17950d7a-333e-43df-a545-cbd5eb3e7447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MISSING GEOMETRY\n",
    "# last file to still have it (og file doesn't either but thats where it's generated)\n",
    "last_file = \"data_v03_observations_catchment_fuelpars.parquet\"\n",
    "\n",
    "# first file to not have it\n",
    "# this file is created by 03_extract_rock_type.ipynb\n",
    "next_file = \"data_v04_rocktype.parquet\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a2da2b-8591-468a-9d01-042f93d39ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# old file names and new file names\n",
    "# replaced in notebooks but haven't tested yet\n",
    "\n",
    "files = {\n",
    "    # current: new\n",
    "    # prep_01\n",
    "    \"staley16_debrisflow.parquet\": \"data_v01_add_site_ids.parquet\",\n",
    "    # prep_02\n",
    "    \"staley16_sites_catchment_fuelpars_v3.parquet\": \"data_v02_sites_catchment_fuelpars.parquet\",\n",
    "    \"staley16_observations_catchment_fuelpars_v3.parquet\": \"data_v03_observations_catchment_fuelpars.parquet\",\n",
    "    # prep 03\n",
    "    \"staley16_observations_catchment_fuelpars_rocktype_v3.parquet\": \"data_v04_rocktype.parquet\",\n",
    "    # prep 04\n",
    "    \"staley16_observations_catchment_fuelpars_rocktype_randn_v3.parquet\", \"data_v05_rocktype_randn.parquet\",\n",
    "    # prep 06\n",
    "    \"staley16_observations_catchment_fuelpars_rocktype_randn_rockAge_v4.parquet\", \"data_v06_geological_age.parquet\",\n",
    "    # prep 07\n",
    "    \"staley16_observations_catchment_fuelpars_rocktype_randn_lndslide_v5.parquet\", \"data_v07_landslide.parquet\",\n",
    "    # prep 08\n",
    "    \"staley16_observations_catchment_fuelpars_rocktype_randn_lndslide_fireinterval_v6.parquet\", \"data_v08_fire_interval.parquet\",\n",
    "    # prep 09\n",
    "    \"\": \"\",\n",
    "    \"\": \"\",\n",
    "    \"\": \"\",\n",
    "    \"\", \"\",\n",
    "    \"\", \"\",\n",
    "    \"\", \"\",\n",
    "    \"\", \"\",\n",
    "    \n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42af7cf3-7ef0-4f68-a726-fa273f9f8ff8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bddad7f1-4927-40a2-9a12-98193ccae441",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fire Name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Fire_ID</th>\n",
       "      <th>Fire_SegID</th>\n",
       "      <th>Database</th>\n",
       "      <th>State</th>\n",
       "      <th>UTM_Zone</th>\n",
       "      <th>UTM_X</th>\n",
       "      <th>UTM_Y</th>\n",
       "      <th>Response</th>\n",
       "      <th>...</th>\n",
       "      <th>Peak_I15_mm/h</th>\n",
       "      <th>Peak_I30_mm/h</th>\n",
       "      <th>Peak_I60_mm/h</th>\n",
       "      <th>ContributingArea_km2</th>\n",
       "      <th>PropHM23</th>\n",
       "      <th>dNBR/1000</th>\n",
       "      <th>KF</th>\n",
       "      <th>Acc015_mm</th>\n",
       "      <th>Acc030_mm</th>\n",
       "      <th>Acc060_mm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Buckweed</td>\n",
       "      <td>2007</td>\n",
       "      <td>bck</td>\n",
       "      <td>bck_1035</td>\n",
       "      <td>Training</td>\n",
       "      <td>CA</td>\n",
       "      <td>11</td>\n",
       "      <td>368133.5165</td>\n",
       "      <td>3823231.989</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.378767</td>\n",
       "      <td>0.217933</td>\n",
       "      <td>0.297853</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Buckweed</td>\n",
       "      <td>2007</td>\n",
       "      <td>bck</td>\n",
       "      <td>bck_1090</td>\n",
       "      <td>Training</td>\n",
       "      <td>CA</td>\n",
       "      <td>11</td>\n",
       "      <td>367871.0165</td>\n",
       "      <td>3822984.489</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.689615</td>\n",
       "      <td>0.061249</td>\n",
       "      <td>0.224896</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Buckweed</td>\n",
       "      <td>2007</td>\n",
       "      <td>bck</td>\n",
       "      <td>bck_1570</td>\n",
       "      <td>Training</td>\n",
       "      <td>CA</td>\n",
       "      <td>11</td>\n",
       "      <td>367503.5165</td>\n",
       "      <td>3821741.989</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.757312</td>\n",
       "      <td>0.042968</td>\n",
       "      <td>0.065537</td>\n",
       "      <td>0.248541</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Buckweed</td>\n",
       "      <td>2007</td>\n",
       "      <td>bck</td>\n",
       "      <td>bck_235</td>\n",
       "      <td>Training</td>\n",
       "      <td>CA</td>\n",
       "      <td>11</td>\n",
       "      <td>371108.5165</td>\n",
       "      <td>3824991.989</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.613415</td>\n",
       "      <td>0.092164</td>\n",
       "      <td>0.141711</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Buckweed</td>\n",
       "      <td>2007</td>\n",
       "      <td>bck</td>\n",
       "      <td>bck_363</td>\n",
       "      <td>Training</td>\n",
       "      <td>CA</td>\n",
       "      <td>11</td>\n",
       "      <td>370763.5165</td>\n",
       "      <td>3824576.989</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.538875</td>\n",
       "      <td>0.058353</td>\n",
       "      <td>0.210158</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Fire Name  Year Fire_ID Fire_SegID  Database State  UTM_Zone        UTM_X  \\\n",
       "0  Buckweed  2007     bck   bck_1035  Training    CA        11  368133.5165   \n",
       "1  Buckweed  2007     bck   bck_1090  Training    CA        11  367871.0165   \n",
       "2  Buckweed  2007     bck   bck_1570  Training    CA        11  367503.5165   \n",
       "3  Buckweed  2007     bck    bck_235  Training    CA        11  371108.5165   \n",
       "4  Buckweed  2007     bck    bck_363  Training    CA        11  370763.5165   \n",
       "\n",
       "         UTM_Y  Response  ... Peak_I15_mm/h  Peak_I30_mm/h Peak_I60_mm/h  \\\n",
       "0  3823231.989         0  ...           3.2            2.0           2.0   \n",
       "1  3822984.489         0  ...           3.2            2.0           2.0   \n",
       "2  3821741.989         0  ...           3.2            2.0           2.0   \n",
       "3  3824991.989         0  ...           1.6            1.2           0.8   \n",
       "4  3824576.989         0  ...           1.6            1.2           0.8   \n",
       "\n",
       "  ContributingArea_km2  PropHM23  dNBR/1000        KF  Acc015_mm  Acc030_mm  \\\n",
       "0             0.378767  0.217933   0.297853  0.250000        0.8        1.0   \n",
       "1             0.689615  0.061249   0.224896  0.250000        0.8        1.0   \n",
       "2             2.757312  0.042968   0.065537  0.248541        0.8        1.0   \n",
       "3             0.613415  0.092164   0.141711  0.250000        0.4        0.6   \n",
       "4             0.538875  0.058353   0.210158  0.250000        0.4        0.6   \n",
       "\n",
       "   Acc060_mm  \n",
       "0        2.0  \n",
       "1        2.0  \n",
       "2        2.0  \n",
       "3        0.8  \n",
       "4        0.8  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = \"../data/ofr20161106_appx-1.xlsx\"\n",
    "xl = pd.ExcelFile(file)\n",
    "sheets = xl.sheet_names\n",
    "raw_data = pd.read_excel(file, sheet_name=sheets[1])\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b6750da-4d55-4dbb-88ed-b4efd11dca05",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fire Name                 0\n",
       "Year                      0\n",
       "Fire_ID                   0\n",
       "Fire_SegID                0\n",
       "Database                  0\n",
       "State                     0\n",
       "UTM_Zone                  0\n",
       "UTM_X                     0\n",
       "UTM_Y                     0\n",
       "Response                  0\n",
       "StormDate                 0\n",
       "GaugeDist_m               0\n",
       "StormStart              160\n",
       "StormEnd                160\n",
       "StormDur_H                0\n",
       "StormAccum_mm             0\n",
       "StormAvgI_mm/h            0\n",
       "Peak_I15_mm/h           230\n",
       "Peak_I30_mm/h           214\n",
       "Peak_I60_mm/h           256\n",
       "ContributingArea_km2      0\n",
       "PropHM23                  0\n",
       "dNBR/1000                77\n",
       "KF                        0\n",
       "Acc015_mm               230\n",
       "Acc030_mm               214\n",
       "Acc060_mm               256\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "53627be4-2d34-47b1-9e15-cd052e1309a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    59\n",
       "1    18\n",
       "Name: Response, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I feel like we could impute these\n",
    "raw_data[raw_data['dNBR/1000'].isna()]['Response'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8f53ea4-1004-4e39-80dd-81a21de4bccc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    230\n",
       "Name: Response, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data[raw_data['Peak_I15_mm/h'].isna()]['Response'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b48dae1-603f-4d78-bc84-4a80e861c03a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    208\n",
       "1      6\n",
       "Name: Response, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data[raw_data['Peak_I30_mm/h'].isna()]['Response'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58b2e60d-0c38-4ab3-9fe3-4292866f243d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(214, 27)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data[raw_data['Peak_I30_mm/h'].isna()].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "242f9ce7-d47f-4ea7-b161-c9fea215d4bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "185"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data[raw_data['Peak_I30_mm/h'].isna()]['Peak_I15_mm/h'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "383726d1-6319-43b7-985d-54212013f96a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    23\n",
       "1     6\n",
       "Name: Response, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data[(raw_data['Peak_I30_mm/h'].isna()) & (raw_data['Peak_I15_mm/h'].notna())]['Response'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8019f308-0235-4df5-81dd-5ccad41b898a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    100\n",
       "1     34\n",
       "Name: Response, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data[(raw_data['Peak_I60_mm/h'].isna()) & (raw_data['Peak_I15_mm/h'].notna())]['Response'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccaa363-7ec1-4162-94c5-357499521967",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83b940a4-9d7f-469c-9eb0-345bc4fc0caa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../model/\")\n",
    "from ModelNN import Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d05d104a-635a-48ae-b5d8-3d96605d2721",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ModelNN import OneLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c008b347-92e8-4bde-969f-cc2b1c54472c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ModelNN as net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "98ad891a-5bbb-4e2e-a600-3483f8c35cda",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "OneLayer.__init__() missing 4 required positional arguments: 'input_size', 'hidden_size', 'output_size', and 'dropout_rate'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOneLayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: OneLayer.__init__() missing 4 required positional arguments: 'input_size', 'hidden_size', 'output_size', and 'dropout_rate'"
     ]
    }
   ],
   "source": [
    "net.OneLayer("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21dc838a-c9d2-4c42-9645-1e41cf681d80",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mModelNN\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Net\n",
      "\u001b[0;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "from ..model.ModelNN import Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa905e8b-bfc4-40dc-ab1c-aae1962e9faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "944b6f56-ac89-4f78-8fa6-3b38214fcd7d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2752027499.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[7], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    import ..model.ModelNN\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import ..model.ModelNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aaf24bc-ef38-4cee-89f3-3fd4d5a61365",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13abf4c4-c7f7-45a7-a7e5-27e2784e813a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef3af0b-9d81-4525-a38c-60209da958fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef527997-0762-4005-a1d4-5acce0bb8eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WORKING CODE\n",
    "\n",
    "%%time\n",
    "# GRID SEARCH CV for hyperpameters\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # data already loaded\n",
    "\n",
    "    #scale the data X_train and X_test\n",
    "    cols = X_train_df.columns\n",
    "    sc = StandardScaler()\n",
    "    # the \"scaled\" objects are still dataframes\n",
    "    X_train_scaled = pd.DataFrame(sc.fit_transform(X_train_df), columns=cols)\n",
    "    X_test_scaled = pd.DataFrame(sc.transform(X_test_df), columns=cols)\n",
    "    \n",
    "    # convert to tensor objects\n",
    "    X_train_tensor = torch.tensor(X_train_scaled.values).float()\n",
    "    y_train_tensor = torch.tensor(y_train_df.values).float().view(-1, 1)\n",
    "    X_test_tensor = torch.tensor(X_test_scaled.values).float()\n",
    "    y_test_tensor = torch.tensor(y_test_df.values).float().view(-1, 1)\n",
    "\n",
    "    # GRID SEARCH\n",
    "    # these are the hyperparameters to search through\n",
    "    param_grid = {\n",
    "    'hidden_size': [10, 50, 100, 250, 500],\n",
    "    'dropout_rate': [0.05, 0.10, 0.15, 0.20],\n",
    "    'lr': [0.0001, 0.001, 0.01],\n",
    "    }\n",
    "    \n",
    "    # instantiate zero-based values to improve upon and log\n",
    "    best_accuracy = 0.0\n",
    "    best_recall = 0.0\n",
    "    best_auc = 0.0\n",
    "    best_params ={}\n",
    "    \n",
    "    for params in ParameterGrid(param_grid):\n",
    "        input_size = X_train_df.shape[1]\n",
    "        hidden_size = params['hidden_size']\n",
    "        output_size = 1 # for our uses this will always be 0ne\n",
    "        dropout_rate = params['dropout_rate']\n",
    "        learning_rate = params['lr']\n",
    "\n",
    "        # instantiate the model class\n",
    "        #model = Net.OneLayer(input_size, hidden_size, output_size, dropout_rate)\n",
    "        model = Net.TwoLayer(input_size, hidden_size, output_size, dropout_rate)\n",
    "        #model = Net.ThreeLayer(input_size, hidden_size, output_size, dropout_rate)\n",
    "\n",
    "        criterion = nn.BCELoss()  # cross-entropy better suited for binary classification than MSE\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)  \n",
    "        \n",
    "        # best_params = grid_search.best_params_\n",
    "        # best_model = grid_search.best_estimator_\n",
    "     \n",
    "        num_epochs = n_epochs\n",
    "\n",
    "        # # empty df to track loss over epochs\n",
    "        # loss_df = pd.DataFrame(columns=['train_loss', 'test_loss'])\n",
    "        \n",
    "        n = 0\n",
    "        for epoch in range(num_epochs):\n",
    "            y_train_pred_proba = model(X_train_tensor)\n",
    "            loss = criterion(y_train_pred_proba, y_train_tensor)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # n += 1\n",
    "            # print(n)            \n",
    "            \n",
    "\n",
    "        ## now \"final\" probability outputs from trained model ##\n",
    "        y_train_pred_proba = model(X_train_tensor)\n",
    "        y_test_pred_proba = model(X_test_tensor)     \n",
    "        \n",
    "        # loss on the final output\n",
    "        # this isn't really meaningful without seeing change over epochs \n",
    "        # occasionally handy to reference\n",
    "        train_loss = criterion(y_train_pred_proba, y_train_tensor)\n",
    "        val_loss = criterion(y_test_pred_proba, y_test_tensor)\n",
    "\n",
    "        # # convert these values back to pandas dtypes\n",
    "        y_train_pred_proba = y_train_pred_proba.detach().numpy()\n",
    "        y_test_pred_proba = y_test_pred_proba.detach().numpy()   \n",
    "        # also get their boolean values\n",
    "        # simply if a probability is above .5 it predicts a 1\n",
    "        #y_train_pred_bool = np.round(y_train_pred_proba.detach().numpy()).flatten()\n",
    "        #y_test_pred_bool = np.round(y_test_pred_proba.detach().numpy()).flatten()\n",
    "        y_train_pred_bool = np.round(y_train_pred_proba)\n",
    "        y_test_pred_bool = np.round(y_test_pred_proba)\n",
    "        \n",
    "        # calculate accuracy\n",
    "        test_pred_correct = sum(y_test_df == y_test_pred_bool.flatten())\n",
    "        test_accuracy = (test_pred_correct / y_test_df.shape[0])\n",
    "        \n",
    "        # calculate recall\n",
    "        test_recall_score = recall_score(y_test_df, y_test_pred_bool, average='binary')\n",
    "        \n",
    "        # extract AUC for printing\n",
    "        auc_test = roc_auc_score(\n",
    "            y_test_df, \n",
    "            y_test_pred_proba\n",
    "        )\n",
    "        \n",
    "        # multiple criteria options for optimizing the network\n",
    "        ## accuracy\n",
    "        ## recall (minimize false negatives)\n",
    "        ## AUC\n",
    "        \n",
    "#         # evaluating parameters on test accuracy\n",
    "#         if test_accuracy > best_accuracy:\n",
    "#             best_accuracy = test_accuracy\n",
    "#             best_params = params\n",
    "\n",
    "#         # evaluating parameters on test recall\n",
    "#         if test_recall_score > best_recall:\n",
    "#             best_recall = test_recall_score\n",
    "#             best_params = params\n",
    "        \n",
    "        # evaluating parameters on test AUC\n",
    "        if auc_test > best_auc:\n",
    "            best_auc = auc_test\n",
    "            best_params = params\n",
    "\n",
    "    # save final model weights\n",
    "    # model_name = \"model\"\n",
    "    # torch.save(model.state_dict(), f'{model_name}.pth')     \n",
    "    \n",
    "    print('best hyperparameters:')\n",
    "    print(best_params)\n",
    "    \n",
    "    print(f'Training loss: {train_loss}')\n",
    "    print(f'Validation loss: {val_loss}')\n",
    "\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    # accuracy #\n",
    "    # training accuracy\n",
    "    train_pred_correct = sum(y_train_df == y_train_pred_bool.flatten())\n",
    "    train_accuracy = (train_pred_correct / y_train_df.shape[0])\n",
    "    print(f'Training accuracy: {train_accuracy}')\n",
    "    # testing accuracy\n",
    "    test_pred_correct = sum(y_test_df == y_test_pred_bool.flatten())\n",
    "    test_accuracy = (test_pred_correct / y_test_df.shape[0])\n",
    "    print(f'Test accuracy: {test_accuracy}')\n",
    "    \n",
    "    # Recall\n",
    "    print(\"\\n\")\n",
    "    print(f'Test Recall: {test_recall_score}')\n",
    "    \n",
    "    # AUC\n",
    "    print(\"\\n\")\n",
    "    print(f'Test AUC: {auc_test}')\n",
    "    # f1\n",
    "    f1_output = f1_score(y_test_df, y_test_pred_bool)\n",
    "    print(\"\\n\")\n",
    "    print(f'Test F1 Score: {f1_output}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580f1b11-6376-4424-99ec-525bf7ab7dda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e274b394-4a1a-42da-bf50-898f68d5d563",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09044501-c1d2-4406-bfe3-717240733ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# GRID SEARCH CV top optimize feature selection\n",
    "\n",
    "# 15 MIN\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # GRID SEARCH\n",
    "    param_grid = {\n",
    "    'hidden_size': [10, 50, 100, 250, 500],\n",
    "    'dropout_rate': [0.05, 0.10, 0.15, 0.20],\n",
    "    'lr': [0.0001, 0.001, 0.01],\n",
    "    'features': feat_of_feats # list of lists\n",
    "    }\n",
    "    \n",
    "    best_accuracy = 0.0\n",
    "    best_recall = 0.0\n",
    "    best_auc = 0.0\n",
    "    best_params ={}\n",
    "    \n",
    "    for params in ParameterGrid(param_grid):\n",
    "        \n",
    "        # Load data\n",
    "        \n",
    "        # splitting already conducted\n",
    "        # using df objects to avoid tensor issues\n",
    "        X_train = X_train_df[params['features']]\n",
    "        X_test = X_test_df[params['features']]\n",
    "        y_train = y_train_df\n",
    "        y_test = y_test_df\n",
    "\n",
    "        #scale the data X_train and X_test\n",
    "        cols = X_train.columns\n",
    "        sc = StandardScaler()\n",
    "        X_train = pd.DataFrame(sc.fit_transform(X_train), columns=cols)\n",
    "        X_test = pd.DataFrame(sc.transform(X_test), columns=cols)\n",
    "\n",
    "        X_train_tensor = torch.tensor(X_train.values).float()\n",
    "        y_train_tensor = torch.tensor(y_train.values).float().view(-1, 1)\n",
    "        X_test_tensor = torch.tensor(X_test.values).float()\n",
    "        y_test_tensor = torch.tensor(y_test.values).float().view(-1, 1)\n",
    "        \n",
    "        \n",
    "        input_size = X_train.shape[1]\n",
    "        hidden_size = params['hidden_size']\n",
    "        output_size = 1\n",
    "        dropout_rate = params['dropout_rate']\n",
    "        learning_rate = params['lr']\n",
    "\n",
    "        # instantiate the model class\n",
    "        #model = Net.OneLayer(input_size, hidden_size, output_size, dropout_rate)\n",
    "        model = Net.TwoLayer(input_size, hidden_size, output_size, dropout_rate)\n",
    "        #model = Net.ThreeLayer(input_size, hidden_size, output_size, dropout_rate)\n",
    "\n",
    "        criterion = nn.BCELoss()  # cross-entropy better suited for binary classification than MSE\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)  \n",
    "         \n",
    "        ## Train the Model ##\n",
    "        \n",
    "        # this is redundant but can be handy for dev\n",
    "        num_epochs = n_epochs\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            y_train_pred_proba = model(X_train_tensor)\n",
    "            loss = criterion(y_train_pred_proba, y_train_tensor)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "        # now \"final\" outputs\n",
    "        y_train_pred_proba = model(X_train_tensor)\n",
    "        y_test_pred_proba = model(X_test_tensor)\n",
    "\n",
    "        # loss on the final output\n",
    "        # this isn't really meaningful without seeing change over epochs \n",
    "        # occasionally handy to reference\n",
    "        train_loss = criterion(y_train_pred_proba, y_train_tensor)\n",
    "        val_loss = criterion(y_test_pred_proba, y_test_tensor)\n",
    "\n",
    "        # # convert these values back to pandas dtypes\n",
    "        y_train_pred_proba = y_train_pred_proba.detach().numpy()\n",
    "        y_test_pred_proba = y_test_pred_proba.detach().numpy()   \n",
    "        # also get their boolean values\n",
    "        # simply if a probability is above .5 it predicts a 1\n",
    "        y_train_pred_bool = np.round(y_train_pred_proba)\n",
    "        y_test_pred_bool = np.round(y_test_pred_proba)   \n",
    "        \n",
    "   \n",
    "        # calculate accuracy\n",
    "        test_pred_correct = sum(y_test == y_test_pred_bool.flatten())\n",
    "        test_accuracy = (test_pred_correct / y_test.shape[0])\n",
    "        \n",
    "        # calculate recall\n",
    "        test_recall_score = recall_score(y_test, y_test_pred_bool, average='binary')\n",
    "        \n",
    "        # extract AUC for printing\n",
    "        auc_test = roc_auc_score(\n",
    "            y_test, \n",
    "            y_test_pred_proba\n",
    "        )\n",
    "\n",
    "        # multiple criteria options for optimizing the network\n",
    "        ## accuracy\n",
    "        ## recall (minimize false negatives)\n",
    "        ## AUC\n",
    "        \n",
    "        # # evaluating parameters on test accuracy\n",
    "        # if test_accuracy > best_accuracy:\n",
    "        #     best_accuracy = test_accuracy\n",
    "        #     best_params = params\n",
    "\n",
    "        # # evaluating parameters on test recall\n",
    "        # if test_recall_score > best_recall:\n",
    "        #     best_recall = test_recall_score\n",
    "        #     best_params = params\n",
    "\n",
    "        # evaluating parameters on test AUC\n",
    "        if auc_test > best_auc:\n",
    "            best_auc = auc_test\n",
    "            best_params = params\n",
    "\n",
    "    # save final model weights\n",
    "    # model_name = \"model\"\n",
    "    # torch.save(model.state_dict(), f'{model_name}.pth')      \n",
    "    \n",
    "    print('with feature selection')\n",
    "    print('best hyperparameters:')\n",
    "    print(best_params)\n",
    "    \n",
    "    print(f'Training loss: {train_loss}')\n",
    "    print(f'Validation loss: {val_loss}')\n",
    "\n",
    "    print(\"\\n\")\n",
    "\n",
    "    ## accuracy ##\n",
    "    # training accuracy\n",
    "    train_pred_correct = sum(y_train == y_train_pred_bool.flatten())\n",
    "    train_accuracy = (train_pred_correct / y_train.shape[0])\n",
    "    print(f'Training accuracy: {train_accuracy}')\n",
    "    # testing accuracy\n",
    "    test_pred_correct = sum(y_test == y_test_pred_bool.flatten())\n",
    "    test_accuracy = (test_pred_correct / y_test.shape[0])\n",
    "    print(f'Test accuracy: {test_accuracy}')\n",
    "    \n",
    "    # Recall\n",
    "    test_recall_score = recall_score(y_test, y_test_pred_bool.flatten(), average='binary')\n",
    "    print(\"\\n\")\n",
    "    print(f'Test Recall: {test_recall_score}')    \n",
    "    \n",
    "    # AUC\n",
    "    print(\"\\n\")\n",
    "    print(f'Test AUC): {auc_test}')\n",
    "    # f1\n",
    "    f1_output = f1_score(y_test, y_test_pred_bool)\n",
    "    print(f'Test F1 Score: {f1_output}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aaace9e-455b-4c31-80a1-17b1c7277485",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bcb713-1c6f-48be-8d80-3c37405ac22f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f3ac1c21-c27b-4eee-94c4-0164f1df097c",
   "metadata": {},
   "source": [
    "# Fire Interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0d838477-01b0-46e6-aa7a-6afacbf3e42c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fire Name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Fire_ID</th>\n",
       "      <th>Fire_SegID</th>\n",
       "      <th>Database</th>\n",
       "      <th>State</th>\n",
       "      <th>UTM_Zone</th>\n",
       "      <th>UTM_X</th>\n",
       "      <th>UTM_Y</th>\n",
       "      <th>Response</th>\n",
       "      <th>...</th>\n",
       "      <th>Peak_I15_mm/h</th>\n",
       "      <th>Peak_I30_mm/h</th>\n",
       "      <th>Peak_I60_mm/h</th>\n",
       "      <th>ContributingArea_km2</th>\n",
       "      <th>PropHM23</th>\n",
       "      <th>dNBR/1000</th>\n",
       "      <th>KF</th>\n",
       "      <th>Acc015_mm</th>\n",
       "      <th>Acc030_mm</th>\n",
       "      <th>Acc060_mm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Buckweed</td>\n",
       "      <td>2007</td>\n",
       "      <td>bck</td>\n",
       "      <td>bck_1035</td>\n",
       "      <td>Training</td>\n",
       "      <td>CA</td>\n",
       "      <td>11</td>\n",
       "      <td>368133.5165</td>\n",
       "      <td>3823231.989</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.378767</td>\n",
       "      <td>0.217933</td>\n",
       "      <td>0.297853</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Buckweed</td>\n",
       "      <td>2007</td>\n",
       "      <td>bck</td>\n",
       "      <td>bck_1090</td>\n",
       "      <td>Training</td>\n",
       "      <td>CA</td>\n",
       "      <td>11</td>\n",
       "      <td>367871.0165</td>\n",
       "      <td>3822984.489</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.689615</td>\n",
       "      <td>0.061249</td>\n",
       "      <td>0.224896</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Buckweed</td>\n",
       "      <td>2007</td>\n",
       "      <td>bck</td>\n",
       "      <td>bck_1570</td>\n",
       "      <td>Training</td>\n",
       "      <td>CA</td>\n",
       "      <td>11</td>\n",
       "      <td>367503.5165</td>\n",
       "      <td>3821741.989</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.757312</td>\n",
       "      <td>0.042968</td>\n",
       "      <td>0.065537</td>\n",
       "      <td>0.248541</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Buckweed</td>\n",
       "      <td>2007</td>\n",
       "      <td>bck</td>\n",
       "      <td>bck_235</td>\n",
       "      <td>Training</td>\n",
       "      <td>CA</td>\n",
       "      <td>11</td>\n",
       "      <td>371108.5165</td>\n",
       "      <td>3824991.989</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.613415</td>\n",
       "      <td>0.092164</td>\n",
       "      <td>0.141711</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Buckweed</td>\n",
       "      <td>2007</td>\n",
       "      <td>bck</td>\n",
       "      <td>bck_363</td>\n",
       "      <td>Training</td>\n",
       "      <td>CA</td>\n",
       "      <td>11</td>\n",
       "      <td>370763.5165</td>\n",
       "      <td>3824576.989</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.538875</td>\n",
       "      <td>0.058353</td>\n",
       "      <td>0.210158</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1545</th>\n",
       "      <td>Wallow</td>\n",
       "      <td>2011</td>\n",
       "      <td>wlw</td>\n",
       "      <td>wlw_47409</td>\n",
       "      <td>Test</td>\n",
       "      <td>AZ</td>\n",
       "      <td>12</td>\n",
       "      <td>660698.3581</td>\n",
       "      <td>3725248.835</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.554356</td>\n",
       "      <td>0.009801</td>\n",
       "      <td>0.187053</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1546</th>\n",
       "      <td>Wallow</td>\n",
       "      <td>2011</td>\n",
       "      <td>wlw</td>\n",
       "      <td>wlw_47535</td>\n",
       "      <td>Test</td>\n",
       "      <td>AZ</td>\n",
       "      <td>12</td>\n",
       "      <td>660178.3581</td>\n",
       "      <td>3725128.835</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>63.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.683425</td>\n",
       "      <td>0.001571</td>\n",
       "      <td>0.500223</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.75</td>\n",
       "      <td>27.0</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1547</th>\n",
       "      <td>Wallow</td>\n",
       "      <td>2011</td>\n",
       "      <td>wlw</td>\n",
       "      <td>wlw_47535</td>\n",
       "      <td>Test</td>\n",
       "      <td>AZ</td>\n",
       "      <td>12</td>\n",
       "      <td>660178.3581</td>\n",
       "      <td>3725128.835</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>29.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.683425</td>\n",
       "      <td>0.001571</td>\n",
       "      <td>0.500223</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.25</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1548</th>\n",
       "      <td>Wallow</td>\n",
       "      <td>2011</td>\n",
       "      <td>wlw</td>\n",
       "      <td>wlw_47535</td>\n",
       "      <td>Test</td>\n",
       "      <td>AZ</td>\n",
       "      <td>12</td>\n",
       "      <td>660178.3581</td>\n",
       "      <td>3725128.835</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.683425</td>\n",
       "      <td>0.001571</td>\n",
       "      <td>0.500223</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.25</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1549</th>\n",
       "      <td>Wallow</td>\n",
       "      <td>2011</td>\n",
       "      <td>wlw</td>\n",
       "      <td>wlw_47535</td>\n",
       "      <td>Test</td>\n",
       "      <td>AZ</td>\n",
       "      <td>12</td>\n",
       "      <td>660178.3581</td>\n",
       "      <td>3725128.835</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.683425</td>\n",
       "      <td>0.001571</td>\n",
       "      <td>0.500223</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1550 rows  27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Fire Name  Year Fire_ID Fire_SegID  Database State  UTM_Zone  \\\n",
       "0     Buckweed  2007     bck   bck_1035  Training    CA        11   \n",
       "1     Buckweed  2007     bck   bck_1090  Training    CA        11   \n",
       "2     Buckweed  2007     bck   bck_1570  Training    CA        11   \n",
       "3     Buckweed  2007     bck    bck_235  Training    CA        11   \n",
       "4     Buckweed  2007     bck    bck_363  Training    CA        11   \n",
       "...        ...   ...     ...        ...       ...   ...       ...   \n",
       "1545    Wallow  2011     wlw  wlw_47409      Test    AZ        12   \n",
       "1546    Wallow  2011     wlw  wlw_47535      Test    AZ        12   \n",
       "1547    Wallow  2011     wlw  wlw_47535      Test    AZ        12   \n",
       "1548    Wallow  2011     wlw  wlw_47535      Test    AZ        12   \n",
       "1549    Wallow  2011     wlw  wlw_47535      Test    AZ        12   \n",
       "\n",
       "            UTM_X        UTM_Y  Response  ... Peak_I15_mm/h  Peak_I30_mm/h  \\\n",
       "0     368133.5165  3823231.989         0  ...           3.2            2.0   \n",
       "1     367871.0165  3822984.489         0  ...           3.2            2.0   \n",
       "2     367503.5165  3821741.989         0  ...           3.2            2.0   \n",
       "3     371108.5165  3824991.989         0  ...           1.6            1.2   \n",
       "4     370763.5165  3824576.989         0  ...           1.6            1.2   \n",
       "...           ...          ...       ...  ...           ...            ...   \n",
       "1545  660698.3581  3725248.835         0  ...          14.0            8.0   \n",
       "1546  660178.3581  3725128.835         0  ...          63.0           54.0   \n",
       "1547  660178.3581  3725128.835         0  ...          29.0           16.0   \n",
       "1548  660178.3581  3725128.835         0  ...          25.0           16.0   \n",
       "1549  660178.3581  3725128.835         0  ...          14.0            8.0   \n",
       "\n",
       "     Peak_I60_mm/h ContributingArea_km2  PropHM23  dNBR/1000        KF  \\\n",
       "0              2.0             0.378767  0.217933   0.297853  0.250000   \n",
       "1              2.0             0.689615  0.061249   0.224896  0.250000   \n",
       "2              2.0             2.757312  0.042968   0.065537  0.248541   \n",
       "3              0.8             0.613415  0.092164   0.141711  0.250000   \n",
       "4              0.8             0.538875  0.058353   0.210158  0.250000   \n",
       "...            ...                  ...       ...        ...       ...   \n",
       "1545           NaN             1.554356  0.009801   0.187053  0.000000   \n",
       "1546          39.0             0.683425  0.001571   0.500223  0.000000   \n",
       "1547           NaN             0.683425  0.001571   0.500223  0.000000   \n",
       "1548           NaN             0.683425  0.001571   0.500223  0.000000   \n",
       "1549           NaN             0.683425  0.001571   0.500223  0.000000   \n",
       "\n",
       "      Acc015_mm  Acc030_mm  Acc060_mm  \n",
       "0          0.80        1.0        2.0  \n",
       "1          0.80        1.0        2.0  \n",
       "2          0.80        1.0        2.0  \n",
       "3          0.40        0.6        0.8  \n",
       "4          0.40        0.6        0.8  \n",
       "...         ...        ...        ...  \n",
       "1545       3.50        4.0        NaN  \n",
       "1546      15.75       27.0       39.0  \n",
       "1547       7.25        8.0        NaN  \n",
       "1548       6.25        8.0        NaN  \n",
       "1549       3.50        4.0        NaN  \n",
       "\n",
       "[1550 rows x 27 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "file = \"../data/ofr20161106_appx-1.xlsx\"\n",
    "xl = pd.ExcelFile(file)\n",
    "sheets = xl.sheet_names\n",
    "staley = pd.read_excel(file, sheet_name=sheets[1])\n",
    "staley"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0530e320-5bc0-4daf-9b6a-14f4d03b6a60",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Acc015_mm',\n",
       " 'Acc030_mm',\n",
       " 'Acc060_mm',\n",
       " 'ContributingArea_km2',\n",
       " 'Database',\n",
       " 'Fire Name',\n",
       " 'Fire_ID',\n",
       " 'Fire_SegID',\n",
       " 'GaugeDist_m',\n",
       " 'KF',\n",
       " 'Peak_I15_mm/h',\n",
       " 'Peak_I30_mm/h',\n",
       " 'Peak_I60_mm/h',\n",
       " 'PropHM23',\n",
       " 'Response',\n",
       " 'State',\n",
       " 'StormAccum_mm',\n",
       " 'StormAvgI_mm/h',\n",
       " 'StormDate',\n",
       " 'StormDur_H',\n",
       " 'StormEnd',\n",
       " 'StormStart',\n",
       " 'UTM_X',\n",
       " 'UTM_Y',\n",
       " 'UTM_Zone',\n",
       " 'Year',\n",
       " 'dNBR/1000']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(staley.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3717dda4-b721-4552-8f67-b6834ed8e9cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>StormDate</th>\n",
       "      <th>StormStart</th>\n",
       "      <th>StormEnd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2007</td>\n",
       "      <td>2008-01-22 00:00:00</td>\n",
       "      <td>2008-01-21 16:27:00</td>\n",
       "      <td>2008-01-22 19:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007</td>\n",
       "      <td>2008-01-22 00:00:00</td>\n",
       "      <td>2008-01-21 16:27:00</td>\n",
       "      <td>2008-01-22 19:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007</td>\n",
       "      <td>2008-01-22 00:00:00</td>\n",
       "      <td>2008-01-21 16:27:00</td>\n",
       "      <td>2008-01-22 19:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2007</td>\n",
       "      <td>2008-01-22 00:00:00</td>\n",
       "      <td>2008-01-21 15:47:00</td>\n",
       "      <td>2008-01-22 19:39:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007</td>\n",
       "      <td>2008-01-22 00:00:00</td>\n",
       "      <td>2008-01-21 15:47:00</td>\n",
       "      <td>2008-01-22 19:39:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1545</th>\n",
       "      <td>2011</td>\n",
       "      <td>2011-09-07 00:00:00</td>\n",
       "      <td>2011-09-07 15:00:00</td>\n",
       "      <td>2011-09-07 15:55:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1546</th>\n",
       "      <td>2011</td>\n",
       "      <td>2011-07-11 00:00:00</td>\n",
       "      <td>2011-07-11 14:45:00</td>\n",
       "      <td>2011-07-11 16:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1547</th>\n",
       "      <td>2011</td>\n",
       "      <td>2011-07-26 00:00:00</td>\n",
       "      <td>2011-07-26 10:45:00</td>\n",
       "      <td>2011-07-26 11:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1548</th>\n",
       "      <td>2011</td>\n",
       "      <td>2011-08-15 00:00:00</td>\n",
       "      <td>2011-08-15 11:00:00</td>\n",
       "      <td>2011-08-15 12:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1549</th>\n",
       "      <td>2011</td>\n",
       "      <td>2011-09-07 00:00:00</td>\n",
       "      <td>2011-09-07 15:00:00</td>\n",
       "      <td>2011-09-07 15:55:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1550 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Year            StormDate          StormStart            StormEnd\n",
       "0     2007  2008-01-22 00:00:00 2008-01-21 16:27:00 2008-01-22 19:20:00\n",
       "1     2007  2008-01-22 00:00:00 2008-01-21 16:27:00 2008-01-22 19:20:00\n",
       "2     2007  2008-01-22 00:00:00 2008-01-21 16:27:00 2008-01-22 19:20:00\n",
       "3     2007  2008-01-22 00:00:00 2008-01-21 15:47:00 2008-01-22 19:39:00\n",
       "4     2007  2008-01-22 00:00:00 2008-01-21 15:47:00 2008-01-22 19:39:00\n",
       "...    ...                  ...                 ...                 ...\n",
       "1545  2011  2011-09-07 00:00:00 2011-09-07 15:00:00 2011-09-07 15:55:00\n",
       "1546  2011  2011-07-11 00:00:00 2011-07-11 14:45:00 2011-07-11 16:15:00\n",
       "1547  2011  2011-07-26 00:00:00 2011-07-26 10:45:00 2011-07-26 11:45:00\n",
       "1548  2011  2011-08-15 00:00:00 2011-08-15 11:00:00 2011-08-15 12:00:00\n",
       "1549  2011  2011-09-07 00:00:00 2011-09-07 15:00:00 2011-09-07 15:55:00\n",
       "\n",
       "[1550 rows x 4 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = [\n",
    "    'Year', # year of wildfire\n",
    "    'StormDate', # date of storm that produced debris-flow response\n",
    "    'StormStart', # date and time that storm started\n",
    "    'StormEnd', # date and time that storm ended\n",
    "    # 'StormAccum_mm',\n",
    "    # 'StormAvgI_mm/h',\n",
    "    # 'StormDur_H',\n",
    "    # 'Peak_I15_mm/h',\n",
    "]\n",
    "\n",
    "staley[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "992e9bd0-9777-48bf-8acc-688a06a6806b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>StormDate</th>\n",
       "      <th>StormStart</th>\n",
       "      <th>StormEnd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2000</td>\n",
       "      <td>2001-07-15 00:00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2000</td>\n",
       "      <td>2001-07-15 00:00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2000</td>\n",
       "      <td>2001-07-15 00:00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2000</td>\n",
       "      <td>2001-07-15 00:00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2000</td>\n",
       "      <td>2001-07-15 00:00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1415</th>\n",
       "      <td>2000</td>\n",
       "      <td>2001-07-15 00:00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1416</th>\n",
       "      <td>2000</td>\n",
       "      <td>2001-07-15 00:00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1417</th>\n",
       "      <td>2000</td>\n",
       "      <td>2001-07-15 00:00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1418</th>\n",
       "      <td>2000</td>\n",
       "      <td>2001-07-15 00:00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1419</th>\n",
       "      <td>2000</td>\n",
       "      <td>2001-07-15 00:00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Year            StormDate StormStart StormEnd\n",
       "26    2000  2001-07-15 00:00:00        NaT      NaT\n",
       "27    2000  2001-07-15 00:00:00        NaT      NaT\n",
       "28    2000  2001-07-15 00:00:00        NaT      NaT\n",
       "29    2000  2001-07-15 00:00:00        NaT      NaT\n",
       "30    2000  2001-07-15 00:00:00        NaT      NaT\n",
       "...    ...                  ...        ...      ...\n",
       "1415  2000  2001-07-15 00:00:00        NaT      NaT\n",
       "1416  2000  2001-07-15 00:00:00        NaT      NaT\n",
       "1417  2000  2001-07-15 00:00:00        NaT      NaT\n",
       "1418  2000  2001-07-15 00:00:00        NaT      NaT\n",
       "1419  2000  2001-07-15 00:00:00        NaT      NaT\n",
       "\n",
       "[160 rows x 4 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "staley[staley['StormStart'].isna()][cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e9fd1972-f34b-411b-9209-128532dddce7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1550, 28) data_v01_add_site_ids.parquet\n",
      "(716, 14) data_v02_sites_catchment_fuelpars.parquet\n",
      "(1550, 42) data_v03_observations_catchment_fuelpars.parquet\n",
      "(1550, 44) data_v04_rocktype.parquet\n",
      "(1550, 44) data_v05_rocktype_randn.parquet\n",
      "(1550, 46) data_v06_geological_age.parquet\n",
      "(1550, 48) data_v07_landslide.parquet\n",
      "(1379, 49) data_v08_fire_interval.parquet\n",
      "(1376, 25) data_v09_consolidated.parquet\n"
     ]
    }
   ],
   "source": [
    "# these NANs are causing downstream effect unecessarily\n",
    "\n",
    "# and for some reason storm date gets parsed incorrectly at some point\n",
    "\n",
    "prefixed = [filename for filename in os.listdir('../data') if filename.startswith(\"data_v\")]\n",
    "prefixed\n",
    "\n",
    "for file in prefixed:\n",
    "    data = gpd.read_parquet(\"../data/\" + file)\n",
    "    print(data.shape, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fba24caa-701c-453c-8bc9-210c1a848bc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "674f4f60-fe25-4fb0-8d1d-d73fd4dfad4a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       22\n",
       "1       22\n",
       "2       22\n",
       "3       22\n",
       "4       22\n",
       "        ..\n",
       "1545     7\n",
       "1546    11\n",
       "1547    26\n",
       "1548    15\n",
       "1549     7\n",
       "Name: stormdate, Length: 1550, dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# it's the first notebook that does it\n",
    "\n",
    "idx = 0\n",
    "check = gpd.read_parquet(\"../data/\" + prefixed[idx])\n",
    "check['stormdate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b48ed663-9b0c-49f0-a760-aa76490dba1a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2010.0    326\n",
       "2009.0    274\n",
       "2002.0    273\n",
       "2008.0    130\n",
       "2003.0     78\n",
       "2013.0     78\n",
       "2011.0     69\n",
       "2006.0     68\n",
       "2012.0     35\n",
       "2005.0     31\n",
       "2007.0     17\n",
       "2000.0     11\n",
       "Name: StormStart, dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime(staley['StormStart']).dt.year.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "74efecd8-3f45-4890-8796-b8be72fdc1b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StormDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>9/10-9/12/2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>9/10-9/12/2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>9/10-9/12/2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>9/10-9/12/2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>9/10-9/12/2002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          StormDate\n",
       "622  9/10-9/12/2002\n",
       "626  9/10-9/12/2002\n",
       "627  9/10-9/12/2002\n",
       "632  9/10-9/12/2002\n",
       "635  9/10-9/12/2002"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = [\n",
    "    #621, # this is a fine one\n",
    "    622,  \n",
    "    626,\n",
    "    627,\n",
    "    632,\n",
    "    635,\n",
    "]\n",
    "\n",
    "check = staley.loc[idx,['StormDate']]\n",
    "check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3a6fb7ca-ae92-483b-9e06-16a800b4eef5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StormDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>9/10-9/12/2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>9/10-9/12/2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>9/10-9/12/2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>9/10-9/12/2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>9/10-9/12/2002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          StormDate\n",
       "622  9/10-9/12/2002\n",
       "626  9/10-9/12/2002\n",
       "627  9/10-9/12/2002\n",
       "632  9/10-9/12/2002\n",
       "635  9/10-9/12/2002"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select records that aren't datetime\n",
    "sel=staley[\"StormDate\"].apply(lambda x: type(x) == str)\n",
    "check = staley.loc[sel,[\"StormDate\"]]\n",
    "check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "37a93d85-bb6c-4040-b9e9-fce73ec5938b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "ff41ce24-479d-4f39-ae2e-5a603b05cd45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# A function that converts these date ranges into day (based on first day of storm)\n",
    "\n",
    "def fix_stormdate(instr):\n",
    "    year=int(instr.split(\"/\")[-1])\n",
    "    month=int(instr.split(\"/\")[1].split(\"-\")[0])\n",
    "    day=int(instr.split(\"/\")[0])\n",
    "    return datetime.date(year, month, day)\n",
    "    #return dt.date(year, month, day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "ac64e050-fbcd-47ca-8287-847a0e9db1d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "622   2002-10-09\n",
       "626   2002-10-09\n",
       "627   2002-10-09\n",
       "632   2002-10-09\n",
       "635   2002-10-09\n",
       "Name: StormDate, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime(check['StormDate'].apply(fix_stormdate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "4d875f50-c79d-4bb7-8793-800d398d136a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2002, 10, 9)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check['StormDate'].apply(fix_stormdate)[622]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "0634f126-c8e4-4d5f-ba54-6ca4db3b728a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2008, 1, 22)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime(staley.loc[0, \"StormDate\"]).date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "ce3b054d-8e9a-45cc-9d6d-8851fd10c494",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "staley.loc[sel, \"StormDate\"] = staley.loc[sel, \"StormDate\"].apply(fix_stormdate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "5499009c-dae1-47cb-bb2a-066264f29871",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2008-01-22\n",
       "1       2008-01-22\n",
       "2       2008-01-22\n",
       "3       2008-01-22\n",
       "4       2008-01-22\n",
       "           ...    \n",
       "1545    2011-09-07\n",
       "1546    2011-07-11\n",
       "1547    2011-07-26\n",
       "1548    2011-08-15\n",
       "1549    2011-09-07\n",
       "Name: StormDate, Length: 1550, dtype: object"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "staley['StormDate'] = pd.to_datetime(staley['StormDate']).dt.date\n",
    "\n",
    "staley['StormDate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "a47336d0-d8eb-451e-953c-227deedd0619",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2008\n",
       "1       2008\n",
       "2       2008\n",
       "3       2008\n",
       "4       2008\n",
       "        ... \n",
       "1545    2011\n",
       "1546    2011\n",
       "1547    2011\n",
       "1548    2011\n",
       "1549    2011\n",
       "Name: StormDate, Length: 1550, dtype: int64"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime(staley['StormDate']).dt.year"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
