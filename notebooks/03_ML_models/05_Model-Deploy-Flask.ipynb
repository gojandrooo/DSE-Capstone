{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e24380e-126d-4021-9490-0e24377426d0",
   "metadata": {},
   "source": [
    "# Falsk App POC\n",
    "- The purpose of htis  notebook is to perform POC to deploy a model on on Flask server , which runs locally on the machine.\n",
    "- Once this works, the same script will be made into app.py and deploy it on to AWS EC2 server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf49bff-3bf2-449a-9637-132eba459747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8e30230d-4073-4ab2-a025-f44f3e3edd5f",
   "metadata": {},
   "source": [
    "- Below cell reads the logisticRegressionModel.pkl file, which is a trained ST16 Model LR file.We use this model to make prediction \n",
    "- Once the below cell is run, the app will be serving on localhost:5000 port\n",
    "- Afer succesfull execution of the below cell, we can test this by pasting below URL in the browser http://127.0.0.1:5000/predict/?rainFall=20.4&siteId=2\n",
    "- Here siteId, is the used to identiy a particular record from ST16 data and the rainFall will be used as i15 parameter\n",
    "- we can change the 2 parameters to test the predict function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f62ed9b-8195-41f0-b49c-f22232d21b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:5000\n",
      "\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "127.0.0.1 - - [21/May/2023 19:16:07] \"GET /predict/?rainFall=20.4&siteId=2 HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask,request\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "#read data into pandas df\n",
    "sdf = pd.read_csv(\"../../data/ofr20161106-na-omit.csv\")\n",
    "# add ID column , which can be used to identity a paritculay record\n",
    "sdf['ID'] = np.arange(sdf.shape[0])\n",
    "\n",
    "#load ST16 LR Model from pickle file \n",
    "with open(\"../../data/ST16_LogisticRegressionModel.pkl\",'rb') as file:\n",
    "    lr_model = pickle.load(file)\n",
    "\n",
    "#URL Binding     \n",
    "@app.route('/predict/', methods=['GET'])\n",
    "def predict():\n",
    "    # read parameters from the URL\n",
    "    parameters = request.args.to_dict()\n",
    "    i15 = float(parameters['rainFall'])\n",
    "    siteId = int(parameters['siteId'])\n",
    "    \n",
    "    #identify the site's record\n",
    "    rec = sdf[sdf['ID']==siteId][[\"PropHM23\",\"dNBR/1000\",'KF']]\n",
    "    \n",
    "    # multiply the peak rainfall intensity ( value is derived from parameters)\n",
    "    rec[\"PropHM23_x_i15\"] = rec[\"PropHM23\"] * i15\n",
    "    rec[\"dNBR_x_i15\"] = rec[\"dNBR/1000\"] * i15\n",
    "    rec[\"KF_x_i15\"] = rec[\"KF\"] * i15\n",
    "\n",
    "    #select the features which are required for model prediction\n",
    "    rec = rec[[\"PropHM23_x_i15\",\"dNBR_x_i15\",\"KF_x_i15\"]]\n",
    "\n",
    "    #predict\n",
    "    y_test_pred = lr_model.predict(rec)   \n",
    "    #return the output\n",
    "    return 'Chance of having debris flow : %s' %y_test_pred[0]\n",
    "                 \n",
    "app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad386874-9103-40e6-88c7-9af2e369c215",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b2a35586-67de-4c5f-bc89-e78c1d684e43",
   "metadata": {},
   "source": [
    "- Below is code to read the model from NN model.pth and use to make predictions ( not tested)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2a1e77f0-b254-435d-8968-570465abbd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=27\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import sklearn\n",
    "import os\n",
    "\n",
    "# # visualization libraries\n",
    "from matplotlib import pyplot as plt\n",
    "# plt.style.use('bmh')\n",
    "plt.style.use('dark_background')\n",
    "# plt.style.use('fivethirtyeight')\n",
    "# Have plots display in notebook\n",
    "%matplotlib inline\n",
    "# import seaborn as sns\n",
    "\n",
    "# # ML libraries\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, roc_auc_score, RocCurveDisplay#, roc_curve\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# # for sigmoid function, in case we need to manually implement in LR\n",
    "# from scipy.stats import logistic\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40015297-5e64-49ce-aac5-4d18c7d104fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read data\n",
    "df = modelDataI=gpd.read_parquet(\"../../data/staley16_observations_catchment_fuelpars_rocktype_randn_v3.parquet\")\n",
    "df=df.dropna()\n",
    "df.shape\n",
    "features_15 = [\n",
    "    'peak_i15_mmh', \n",
    "    'contributingarea_km2', \n",
    "    'prophm23',\n",
    "    'dnbr1000', \n",
    "    'kf', \n",
    "    'acc015_mm', \n",
    "    'NB', \n",
    "    'GR', \n",
    "    'GS', \n",
    "    'SH', \n",
    "    'TU', \n",
    "    'TL',\n",
    "    'Fine fuel load', \n",
    "    'SAV', \n",
    "    'Packing ratio', \n",
    "    'Extinction moisture content',\n",
    "    'Igneous', \n",
    "    'Metamorphic', \n",
    "    'Sedimentary', \n",
    "    'Unconsolidated']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c33a743-66c1-4622-81a9-5285c18832ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, dropout_rate):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(dropout_rate) # dropout to prevent overfitting\n",
    "        \n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(dropout_rate) # dropout to prevent overfitting\n",
    "        \n",
    "        self.fc3 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.dropout3 = nn.Dropout(dropout_rate) # dropout to prevent overfitting\n",
    "\n",
    "        self.fc4 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.dropout4 = nn.Dropout(dropout_rate) # dropout to prevent overfitting\n",
    "        \n",
    "        self.fc5 = nn.Linear(hidden_size, output_size)\n",
    "        self.sigmoid = nn.Sigmoid() # output to probability rather than bool\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu1(out)\n",
    "        out = self.dropout1(out)\n",
    "        \n",
    "        out = self.fc2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.dropout2(out)\n",
    "        \n",
    "        out = self.fc3(out)\n",
    "        out = self.relu3(out)\n",
    "        out = self.dropout3(out)\n",
    "        \n",
    "        out = self.fc4(out)\n",
    "        out = self.relu4(out)\n",
    "        out = self.dropout4(out)\n",
    "        \n",
    "        out = self.fc5(out)\n",
    "        out = self.sigmoid(out)      \n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "668b1cff-15a4-4996-b647-8b7e04495fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "F1 Score (test): 0.6486486486486486\n",
      "AUC (test): 0.8543739279588336\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Load data\n",
    "    data = df.copy()\n",
    "    \n",
    "    X = data[features_15]\n",
    "    y = data['response']\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
    "    \n",
    "    #scale the data X_train and X_test\n",
    "    cols = X_train.columns\n",
    "    sc = StandardScaler()\n",
    "    X_train = pd.DataFrame(sc.fit_transform(X_train), columns=cols)\n",
    "    X_test = pd.DataFrame(sc.transform(X_test), columns=cols)\n",
    "    \n",
    "    X_train = torch.tensor(X_train.values).float()\n",
    "    y_train = torch.tensor(y_train.values).float().view(-1, 1)\n",
    "    X_test = torch.tensor(X_test.values).float()\n",
    "    y_test = torch.tensor(y_test.values).float().view(-1, 1)\n",
    "    \n",
    "    input_size = X_train.shape[1]\n",
    "    hidden_size = 500\n",
    "    output_size = 1\n",
    "    dropout_rate = 0.2\n",
    "    learning_rate = 0.001 # 0.001 is default value for Adam optimizer\n",
    "    \n",
    "    model = Net(input_size, hidden_size, output_size, dropout_rate)\n",
    "    model.load_state_dict(torch.load('model.pth'))\n",
    "#     criterion = nn.BCELoss()  # cross-entropy better suited for binary classification than MSE\n",
    " \n",
    "    \n",
    "#     #criterion = nn.BCEWithLogitsLoss(pos_weight=torch.ones([output_size]))\n",
    "#     #criterion = nn.NLLLoss()\n",
    "#     optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "      \n",
    "#     num_epochs = 500\n",
    "    \n",
    "#     # empty df to track loss over epochs\n",
    "#     loss_df = pd.DataFrame(columns=['train_loss', 'test_loss'])\n",
    "    \n",
    "#     for epoch in range(num_epochs):\n",
    "#         y_train_pred = model(X_train)\n",
    "#         loss = criterion(y_train_pred, y_train)\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         if epoch%5 ==0:\n",
    "#             y_train_pred = model(X_train)\n",
    "#             y_test_pred = model(X_test)\n",
    "\n",
    "#             train_loss = criterion(y_train_pred, y_train)\n",
    "#             val_loss = criterion(y_test_pred, y_test)\n",
    "            \n",
    "#             loss_df.loc[epoch, 'train_loss'] = train_loss.detach().numpy().reshape(1)[0]\n",
    "#             loss_df.loc[epoch, 'test_loss'] = val_loss.detach().numpy().reshape(1)[0]\n",
    "\n",
    "# fig = loss_df.plot()\n",
    "# fig.set_xlabel('epochs')\n",
    "# fig.set_ylabel('loss')\n",
    "# fig.set_title('Loss over Epochs');\n",
    "\n",
    "# now final outputs\n",
    "y_train_pred = model(X_train)\n",
    "#y_train_prob = torch.sigmoid(y_train_pred) # already a probability\n",
    "\n",
    "y_test_pred = model(X_test)\n",
    "# y_test_prob = torch.sigmoid(y_test_pred) # already a probability\n",
    "\n",
    "\n",
    "# print(\"\\n\")\n",
    "\n",
    "# # accuracy\n",
    "# train_pred_correct = sum(y_train.detach().numpy() == np.round(y_train_pred.detach().numpy()))\n",
    "# train_accuracy = (train_pred_correct / y_train.shape[0])[0]\n",
    "# print(f'Training accuracy: {train_accuracy}')\n",
    "\n",
    "# test_pred_correct = sum(y_test.detach().numpy() == np.round(y_test_pred.detach().numpy()))\n",
    "# test_accuracy = (test_pred_correct / y_test.shape[0])[0]\n",
    "# print(f'Test accuracy: {test_accuracy}')\n",
    "\n",
    "# # f1\n",
    "f1_output = f1_score(y_test, np.round(y_test_pred.detach().numpy()))\n",
    "print(\"\\n\")\n",
    "print(f'F1 Score (test): {f1_output}')\n",
    "\n",
    "\n",
    "# # extract AUC for printing\n",
    "auc_test = roc_auc_score(\n",
    "    y_test.detach().numpy(), \n",
    "    y_test_pred.detach().numpy()\n",
    ")\n",
    "print(f'AUC (test): {auc_test}')\n",
    "print('\\n')\n",
    "\n",
    "# # and plot AUC\n",
    "# fig, ax = plt.subplots()\n",
    "\n",
    "# RocCurveDisplay.from_predictions(y_train.detach().numpy(), \n",
    "#                                  y_train_pred.detach().numpy(), \n",
    "#                                  ax=ax, \n",
    "#                                  linewidth=1, \n",
    "#                                  color='red', \n",
    "#                                  name='train', \n",
    "#                                  linestyle=\"dashed\"\n",
    "#                                 );\n",
    "\n",
    "# RocCurveDisplay.from_predictions(y_test.detach().numpy(), \n",
    "#                                  y_test_pred.detach().numpy(),\n",
    "#                                  ax=ax, \n",
    "#                                  linewidth=1, \n",
    "#                                  color='yellow', \n",
    "#                                  name='test');\n",
    "\n",
    "# plt.title('FC NN w/ BCELoss: 15 min rain accum.');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5653ad5-feb0-4c09-9320-5fd9438311ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.30.0'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "requests.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "522350fc-c5a0-43b0-acc1-646ee15e976b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Site 0 has 1 rainfall\n",
      "   PropHM23  dNBR/1000    KF\n",
      "1  0.061249   0.224896  0.25\n",
      "   PropHM23_x_i15  dNBR_x_i15  KF_x_i15\n",
      "1        1.249474     4.58787       5.1\n",
      "Chance of having debris flow : 1\n"
     ]
    }
   ],
   "source": [
    "sdf = pd.read_csv(\"../../data/ofr20161106-na-omit.csv\")\n",
    "sdf['ID'] = np.arange(sdf.shape[0])\n",
    "\n",
    "def test():\n",
    "    parameters = {'rainFall':'20.4','siteId':'1'}\n",
    "    i15 = float(parameters['rainFall'])\n",
    "    siteId = int(parameters['siteId'])\n",
    "    print(f'Site {0} has {1} rainfall'.format(i15,siteId))\n",
    "    rec = sdf[sdf['ID']==1][[\"PropHM23\",\"dNBR/1000\",'KF']]\n",
    "    print(rec)\n",
    "    rec[\"PropHM23_x_i15\"] = rec[\"PropHM23\"] * i15\n",
    "    rec[\"dNBR_x_i15\"] = rec[\"dNBR/1000\"] * i15\n",
    "    rec[\"KF_x_i15\"] = rec[\"KF\"] * i15\n",
    "    rec = rec[[\"PropHM23_x_i15\",\"dNBR_x_i15\",\"KF_x_i15\"]]\n",
    "    print(rec[[\"PropHM23_x_i15\",\"dNBR_x_i15\",\"KF_x_i15\"]])\n",
    "    y_test_pred = lr_model.predict(rec)      \n",
    "    return 'Chance of having debris flow : %s' %y_test_pred[0]           \n",
    "\n",
    "print(test())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fff6374-20d0-4a09-9bb3-17829e4c7b2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7c48d36e-f9d7-49df-b4ec-c283366e8f82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          0\n",
       "1          1\n",
       "2          2\n",
       "3          3\n",
       "4          4\n",
       "        ... \n",
       "1086    1086\n",
       "1087    1087\n",
       "1088    1088\n",
       "1089    1089\n",
       "1090    1090\n",
       "Name: ID, Length: 1091, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf['ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fb4559d0-39ad-43f6-bfed-4b3aff122886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sdf['ID']==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4955edda-f35b-4f94-9fee-a523d469815e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PropHM23  dNBR/1000    KF\n",
      "1  0.061249   0.224896  0.25\n",
      "   PropHM23_x_i15  dNBR_x_i15  KF_x_i15\n",
      "1        1.224975    4.497912       5.0\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "sdf = pd.read_csv(\"../../data/ofr20161106-na-omit.csv\")\n",
    "sdf['ID'] = np.arange(sdf.shape[0])\n",
    "i15=20\n",
    "\n",
    "rec = sdf[sdf['ID']==1][[\"PropHM23\",\"dNBR/1000\",'KF']]\n",
    "print(rec)\n",
    "\n",
    "rec[\"PropHM23_x_i15\"] = rec[\"PropHM23\"] * i15\n",
    "rec[\"dNBR_x_i15\"] = rec[\"dNBR/1000\"] * i15\n",
    "rec[\"KF_x_i15\"] = rec[\"KF\"] * i15\n",
    "\n",
    "rec = rec[[\"PropHM23_x_i15\",\"dNBR_x_i15\",\"KF_x_i15\"]]\n",
    "\n",
    "print(rec[[\"PropHM23_x_i15\",\"dNBR_x_i15\",\"KF_x_i15\"]])\n",
    "\n",
    "y_test_pred = lr_model.predict(rec)\n",
    "\n",
    "print(y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27b3f3b-8ef8-428d-a287-f982432cf303",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_debris_flow",
   "language": "python",
   "name": "venv_debris_flow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
