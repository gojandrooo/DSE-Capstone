{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "540864d5-67cf-439e-a368-0810ed7dae8a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded\n"
     ]
    }
   ],
   "source": [
    "# load in the model class\n",
    "import json\n",
    "from sys import path\n",
    "path.append(\"./model/\")\n",
    "import ModelNN as Net\n",
    "import torch\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "\n",
    "#intialize values\n",
    "seed=27\n",
    "data_dir = './data/'\n",
    "model_dir = './model/'\n",
    "architecture = 'TwoLayer_250_epochs_optimized_roc_auc_score' # use whichever model name desired\n",
    "peak_mmh = 'peak_i15_mmh'\n",
    "\n",
    "\n",
    "# open the parameters json\n",
    "file_name = \"model_parameters.json\"\n",
    "with open(model_dir + file_name) as model_params:\n",
    "    model_params = json.load(model_params)\n",
    "# load in model parameters\n",
    "one_model = model_params[architecture]\n",
    "\n",
    "# should turn this into a function\n",
    "input_size = len(one_model['features'])\n",
    "hidden_size = one_model['hidden_size']\n",
    "dropout_rate = one_model['dropout_rate']\n",
    "output_size = 1\n",
    "\n",
    "# model class name\n",
    "model_class = one_model['model_class']\n",
    "# load feature set\n",
    "features = one_model['features']\n",
    "# load trained model weights file_name\n",
    "weights = one_model['weights']\n",
    "\n",
    "# set device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# instantiate model for inference\n",
    "with torch.no_grad(): # turn off gradiants for inference\n",
    "    if model_class == 'OneLayer':\n",
    "        model = Net.OneLayer(input_size, hidden_size, output_size, dropout_rate).to(device)\n",
    "    elif model_class == 'TwoLayer':\n",
    "        model = Net.TwoLayer(input_size, hidden_size, output_size, dropout_rate).to(device)\n",
    "    elif model_class == 'ThreeLayer':\n",
    "        model = Net.ThreeLayer(input_size, hidden_size, output_size, dropout_rate).to(device)\n",
    "    model.eval() # turn off dropout etc for inference\n",
    "# load weights/biases\n",
    "model.load_state_dict(torch.load(model_dir + weights, map_location=device))\n",
    "\n",
    "# LOAD IN DATA\n",
    "# needed to scale to training set\n",
    "#X_train_df, X_test_df, y_train_df, y_test_df = pickle.load(open(data_dir + \"train_test_data.pkl\", \"rb\"))\n",
    "X_train_df, X_test_df, y_train_df, y_test_df = pd.read_pickle(open(data_dir + \"train_test_data.pkl\", \"rb\"))\n",
    "# delete the testing data, we don't need it\n",
    "del X_test_df, y_test_df\n",
    "X_train_df = X_train_df[features]\n",
    "\n",
    "# scale on the training set\n",
    "sc = StandardScaler()\n",
    "X_train_scaled = pd.DataFrame(sc.fit_transform(X_train_df))\n",
    "# we need to extract these for app runtime\n",
    "# these will be used to scale the input data\n",
    "rain_scaler_mean = X_train_df['peak_i15_mmh'].mean()\n",
    "rain_scaler_std = X_train_df['peak_i15_mmh'].std()\n",
    "### for example:\n",
    "#### but swap out \"rain\" with the input paramater\n",
    "#####rain_scaled = (rain - rain_scaler_mean) / rain_scaler_std\n",
    "\n",
    "# now load in all the data\n",
    "site_data = gpd.read_parquet(data_dir + \"sites_v02_plot_data.parquet\")\n",
    "# need for replacing data in scaled df at inference\n",
    "col_idx = site_data[features].columns.get_loc('peak_i15_mmh')\n",
    "\n",
    "# fit the data to the scaler\n",
    "X_scaled = pd.DataFrame(sc.transform(site_data[features]))\n",
    "# change to tensor\n",
    "# X_scaled_tensor = torch.tensor(X_scaled.values).float().to(device)\n",
    "# # make prediction\n",
    "# y_pred_tensor = model(X_scaled_tensor) # already sent to device when instantiated\n",
    "# # convert back dtype\n",
    "# y_pred_proba = y_pred_tensor.detach().cpu().numpy().astype(np.float16) # smaller dtype\n",
    "# y_pred_bool = np.round(y_pred_proba)\n",
    "print('loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcb2b3e9-295f-4e1d-ba0e-328f832487f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# site_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3c77fb3-4510-49fc-927c-10e0521e1c04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# site_data['geom'].crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "daa9344d-3ef9-4086-8ed7-398a573f8b6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# site_data['geometry_simple'].crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ab96409-fc34-42ac-8759-7d41e7c0e293",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # calculate center of map for initializing to our data\n",
    "# # ignore the warning in this case\n",
    "# import warnings\n",
    "# with warnings.catch_warnings():\n",
    "#     warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "\n",
    "#     map_center = {\n",
    "#         \"lon\": site_data['geometry_simple'].centroid.x.median(),\n",
    "#         \"lat\": site_data['geometry_simple'].centroid.y.median(),\n",
    "#     }\n",
    "# map_center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ccd6762-2b07-44ec-a26d-6592587a271e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "states = sorted(site_data['state'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35482fd3-5d09-429b-a177-d4a60c35ed68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# calculate center of map for initializing to our data\n",
    "# ignore the warning in this case\n",
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "\n",
    "    map_centers = {}\n",
    "    map_centers['-'] = {\n",
    "        \"lon\": site_data['geometry_simple'].centroid.x.median(),\n",
    "        \"lat\": site_data['geometry_simple'].centroid.y.median(),\n",
    "\n",
    "    }\n",
    "\n",
    "    for state in states:\n",
    "        state_mask = site_data['state'] == state\n",
    "        map_centers[state] = {\n",
    "                \"lon\": site_data.loc[state_mask,'geometry_simple'].centroid.x.median(),\n",
    "                \"lat\": site_data.loc[state_mask,'geometry_simple'].centroid.y.median(),\n",
    "        }\n",
    "map_center = map_centers['-']\n",
    "#map_centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2ef11c7-141c-4d6a-ba41-a5872307e6db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7efb92447940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# PRODUCTION\n",
    "from dash import Dash, dcc, html, Input, Output\n",
    "import plotly.express as px\n",
    "\n",
    "from jupyter_dash import JupyterDash # for dev\n",
    "app = JupyterDash(__name__) # for dev\n",
    "#app = Dash(__name__)\n",
    "\n",
    "app.layout = html.Div([\n",
    "    html.H1(\"Change the value in the text box to see updated probability of Debris Flow\"),\n",
    "    html.Div([\n",
    "        \"Input Upcoming Rain Forecase (mm/h): \",\n",
    "         dcc.Input(id='rain_input', value='10', type='number', step=\"1\", min=0)\n",
    "    ]),\n",
    "    html.Br(),\n",
    "    html.Div([\n",
    "        dcc.Graph(id='map_plot',\n",
    "        )\n",
    "    ]),\n",
    "])\n",
    "\n",
    "\n",
    "# define initial map function\n",
    "def create_plot(plot_df):\n",
    "       \n",
    "    # create the plot with our new proba\n",
    "    fig = px.choropleth_mapbox(\n",
    "        plot_df,\n",
    "        plot_df['geometry_simple'], # this is the area\n",
    "        locations=plot_df.index, # needed to match all data correctly\n",
    "        color='proba',\n",
    "        range_color=(0, 1),\n",
    "        color_continuous_scale='OrRd',\n",
    "        #color_continuous_scale='RdBu_r',\n",
    "        #color_continuous_scale='Blackbody_r',\n",
    "        hover_name='state',\n",
    "        # format what's displayed\n",
    "        # trouble disabling the index from displayinin hover\n",
    "        hover_data={\n",
    "            'proba':':,.0%',\n",
    "        },\n",
    "        center=map_center,\n",
    "        mapbox_style='stamen-terrain',\n",
    "        height=800,\n",
    "        zoom=7,\n",
    "        opacity=0.5,\n",
    "    )\n",
    "    \n",
    "    fig2 = px.scatter_mapbox(\n",
    "        plot_df,\n",
    "        lat='lat', # point data\n",
    "        lon='lon', # point data\n",
    "        #color_discrete_map={'Debris-Flow': 'orange'},\n",
    "        size_max=6,\n",
    "        hover_data=['flowdate'],\n",
    "        #mapbox_style='stamen-terrain', # not needed when adding traces\n",
    "    )\n",
    "    # combine plots\n",
    "    fig.add_traces(fig2.data)\n",
    "    #fig.show()\n",
    "    #return fig\n",
    "    \n",
    "    fig.update_coloraxes(\n",
    "        colorbar_title='probability',\n",
    "        #colorbar_tick0=0,\n",
    "        cmin=0,\n",
    "        cmax=1,\n",
    "        colorbar_tickformat='.0%',\n",
    "        #color_tickvals=[.0, .1, .2, .3, .4, .5, .6, .7, .8, .9, 1.0],\n",
    "        #colorbar_tickmode='array',# array supposedly default if tickvals works\n",
    "        #colorbar_nticks=10,\n",
    "        #colorbar_dticks=.10,\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='Debris Flow Prediction',\n",
    "        #uirevision='true',\n",
    "        uirevision=True, # sometimes buggy but keeps zoom from resetting when input changes\n",
    "        #coloraxis_colorbar_x=0.01, # move to left side of screen\n",
    "        hoverlabel=dict(\n",
    "            font_size=14,\n",
    "        ),\n",
    "    )\n",
    "    # fig.update_traces(\n",
    "    #     hovertemplate={\n",
    "    #         'proba':':,.0%',\n",
    "    # },)\n",
    "    return fig\n",
    "\n",
    "@app.callback(\n",
    "    #Output(component_id='my_output', component_property='children'),\n",
    "    Output(component_id='map_plot', component_property='figure'),\n",
    "    Input(component_id='rain_input', component_property='value')\n",
    ")\n",
    "\n",
    "def display_map(input_value):\n",
    "    # fit the scaler on the input\n",
    "    rain_arr = pd.to_numeric(np.repeat(input_value, site_data.shape[0]))\n",
    "    rain_arr_scaled = (rain_arr - rain_scaler_mean) / rain_scaler_std\n",
    "    # now replace with the scaled input\n",
    "    X_scaled.loc[:,col_idx] = rain_arr_scaled\n",
    "    # pass to tensor\n",
    "    X_scaled_tensor = torch.tensor(X_scaled.values).float().to(device)\n",
    "    # and make prediction with the new rain amount\n",
    "    y_pred_tensor = model(X_scaled_tensor) # already sent to device when instantiated\n",
    "    # predicted probability, passed back to numpy\n",
    "    y_pred_proba = y_pred_tensor.detach().cpu().numpy().astype(np.float16) # smaller dtype\n",
    "    # in case you want the binary output for something\n",
    "    #y_pred_bool = np.round(y_pred_proba)\n",
    "    site_data['proba'] = y_pred_proba\n",
    "    \n",
    "    return create_plot(site_data)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(\n",
    "        debug=True,\n",
    "        mode='inline',\n",
    "        #host='localhost',\n",
    "        #port=8090,\n",
    "        #dev_tools_ui=True, \n",
    "        #dev_tools_hot_reload=True, \n",
    "        #threaded=True,\n",
    "    )\n",
    "#webbrowser.open(\"http://127.0.0.1:8050/\") # can open automatically to save a click"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
